<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Ordina JWorks Tech Blog</title>
    <description>Ordina JWorks Tech blog
</description>
    <link>https://ordina-jworks.github.io/</link>
    <atom:link href="https://ordina-jworks.github.io/feed.xml" rel="self" type="application/rss+xml"/>
    <pubDate>Wed, 16 Nov 2016 23:11:58 +0000</pubDate>
    <lastBuildDate>Wed, 16 Nov 2016 23:11:58 +0000</lastBuildDate>
    <generator>Jekyll v3.3.1</generator>
    
      <item>
        <title>The Serverless Cloud</title>
        <description>&lt;blockquote&gt;
  &lt;p&gt;In recent years, the uprise of the cloud has brought us a lot of new and disruptive technologies. 
Everybody is talking about SaaS, PaaS, IaaS and other sorts of aaS. 
In 2014, Amazon launched AWS Lambda as the pinnacle of the cloud computing. 
It allows developers to focus on code, without spending time on managing servers.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;part-1&quot;&gt;Part 1&lt;/h1&gt;

&lt;h2 id=&quot;what&quot;&gt;What?&lt;/h2&gt;

&lt;p&gt;While Microservices have been reigning the Cloud landscape for a couple of years, today the Serverless movement is one of the hottest trends in the industry. 
Historically, software developers have been pretty bad at naming things and Serverless is no exception. 
Disregarding what the name suggests, Serverless does not imply the complete absence of servers. 
It implies that developers who are using the Serverless architectural style, are not responsible for managing or provisioning the servers themselves, but use a vendor-supplied Cloud solution. 
Serverless means less worrying about servers. 
Although in the future, it might be possible to install this kind of service on-premise, for example with the open-source &lt;a href=&quot;https://github.com/openwhisk/openwhisk&quot;&gt;IBM OpenWhisk&lt;/a&gt; implementation.&lt;/p&gt;

&lt;p&gt;In regard to this, the definition &lt;a href=&quot;https://twitter.com/marak/status/736357543598002176&quot;&gt;FaaS&lt;/a&gt;: Functions as a Service makes a lot more sense. 
Functions are short-lived pieces of runtime functionality that don’t need a server that’s always running. 
Strictly speaking a function can have a longer execution time, but most FaaS providers will currently limit the allowed computation time. 
When an application calls a function (eg. a calculation algorithm), this function gets instantiated on request. 
When it’s finished, it gets destroyed. 
This leads to a shorter “running” time and thus a significant financial advantage. 
As an example, you can find the AWS Lambda pricing &lt;a href=&quot;https://aws.amazon.com/lambda/pricing/&quot;&gt;here&lt;/a&gt;. 
FaaS functions are also a great match for event-driven behaviour: when an event is dispatched, the function can be started instantly and ran only for the needed time. 
A Serverless application is a composition of event chaining. 
This makes the Serverless style a natural match for &lt;a href=&quot;http://www.slideshare.net/BartBlommaerts/the-collaborative-economy-61528579&quot;&gt;API Economy&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;As a result of being runtime components, FaaS functions are stateless and need to rely on a database (or file system) to store state. 
Being stateless and short-lived naturally lead to extreme horizontal scaling opportunities and all major FaaS providers support these.&lt;/p&gt;

&lt;h2 id=&quot;noops&quot;&gt;NoOps&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;http://searchcloudapplications.techtarget.com/definition/noops&quot;&gt;NoOps&lt;/a&gt; (No Operations) is the concept that an IT environment can become so automated and abstracted from the underlying infrastructure that there is no need for a dedicated team to manage software in-house. 
NoOps isn’t a new concept as this &lt;a href=&quot;http://blogs.forrester.com/mike_gualtieri/11-02-07-i_dont_want_devops_i_want_noops&quot;&gt;article&lt;/a&gt; from 2011 proves. 
When Serverless started gaining popularity, some people claimed there was no longer a need for Operations. 
Since we already established that Serverless doesn’t mean no servers, it’s obvious it also doesn’t mean No Operations.
It might mean that Operations gets outsourced to a team with specialised skills, but we are still going to need: monitoring, security, remote debugging, … 
I am curious to see the impact on current DevOps teams though. 
A very interesting article on the NoOps topic, can be found over &lt;a href=&quot;https://charity.wtf/2016/05/31/operational-best-practices-serverless/&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;aws&quot;&gt;AWS&lt;/h2&gt;

&lt;h3 id=&quot;aws-lambda&quot;&gt;AWS Lambda&lt;/h3&gt;

&lt;p&gt;&lt;a href=&quot;http://aws.amazon.com/documentation/lambda/&quot;&gt;AWS Lambda&lt;/a&gt; was the first major platform to support FaaS functions, running on the AWS infrastructure. 
Currently AWS Lambda supports three languages: Node.js, Java, and Python. 
AWS Lambda can be used both for synchronous and asynchronous services.&lt;/p&gt;

&lt;p&gt;Currently the tooling for AWS Lambda is still relatively immature, but this is changing rapidly. 
At the time of writing, the AWS Lambda console offers the possibility to create a Lambda using blueprints. 
This is already easier than setting up a lambda by hand (using a ZIP-file). 
Blueprints are sample configurations of event sources and Lambda functions. 
Currently 45 blueprints are available. 
To give a short introduction, we’ll select the &lt;strong&gt;hello-world&lt;/strong&gt; blueprint. 
This blueprint generates a very simple NodeJS function:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;'use strict';
console.log('Loading function');
  
exports.handler = (event, context, callback) =&amp;gt; {
   console.log('value1 =', event.key1);
   console.log('value2 =', event.key2);
   console.log('value3 =', event.key3);
   callback(null, event.key1); 
};
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;After creating this function, it can be immediately be tested from the console, using a test event. 
If we want to call this function synchronously, we need to create an API endpoint with the &lt;a href=&quot;https://aws.amazon.com/api-gateway/&quot;&gt;AWS API Gateway&lt;/a&gt;. 
The API Gateway creates API’s that acts as a “front door” to your functions. 
To make this work with the events in our hello-world example, we need to select the resources of our API:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/serverless/1.png&quot; alt=&quot;Serverless&quot; /&gt;&lt;/p&gt;

&lt;p&gt;In Integration Request, we add a body mapping template of type &lt;em&gt;application/json&lt;/em&gt; with the following template:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;key3&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;$input.params('key3')&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;key2&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;$input.params('key2')&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;key1&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;$input.params('key1')&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;In ‘Method request’ we add 3 URL String query parameters: key1, key2 and key3. 
If we then redeploy our API, hitting the Test button gives us an input form to add the 3 query parameters and the function is executed successfully:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/serverless/2.png&quot; alt=&quot;Serverless&quot; /&gt;&lt;/p&gt;

&lt;p&gt;If you want to test this directly from a browser, you will need to change the Auth to NONE in the ‘Method request’ and do a new deploy of the API. 
The URL itself can be found in the ‘stage’-menu.&lt;/p&gt;

&lt;p&gt;This example obviously is not very interesting, so let’s try another blueprint: &lt;em&gt;microservice-http-endpoint&lt;/em&gt;. 
This will generate a CRUD backend, using &lt;a href=&quot;http://aws.amazon.com/dynamodb&quot;&gt;DynamoDB&lt;/a&gt; with a RESTful API endpoint. 
The code generated, covers all common use-cases:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;'use strict';
letdoc = require('dynamodb-doc');
letdynamo = newdoc.DynamoDB();
exports.handler = (event, context, callback) =&amp;gt; {
   const operation = event.operation;
   if(event.tableName) {
      event.payload.TableName = event.tableName;
   }
   switch(operation) {
   case'create':
      dynamo.putItem(event.payload, callback);
      break;
   case'read':
      dynamo.getItem(event.payload, callback);
      break;
   case'update':
      dynamo.updateItem(event.payload, callback);
      break;
   case'delete':
      dynamo.deleteItem(event.payload, callback);
      break;
   case'list':
      dynamo.scan(event.payload, callback);
      break;
   case'echo':
      callback(null, event.payload);
      break;
   case'ping':
      callback(null, 'pong');
      break;
   default:
      callback(newError(`Unrecognized operation &quot;${operation}&quot;`));
   }
};
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Obviously you will need a DynamoDB instance with some data in it:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/serverless/3.png&quot; alt=&quot;Serverless&quot; /&gt;&lt;/p&gt;

&lt;p&gt;You can reference your new table, from your lambda, using the following event:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;tableName&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;garage-car-dev&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;operation&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;list&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;payload&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; 
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;The only difficult part remaining, is finding out the required &lt;a href=&quot;http://docs.aws.amazon.com/lambda/latest/dg/with-on-demand-https-example.html&quot;&gt;payload&lt;/a&gt; for the different operations :) 
This is a good start for creating new records:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;operation&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;create&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;tableName&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;garage-car-dev&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;payload&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
   &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;Item&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
      &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;id&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;1980b61a-f5d7-46e8-b62a-0bbb91e20706&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
      &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;body&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Lamborghini&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
      &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;updatedAt&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;1467559284484&quot;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
      &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
   &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;The blueprint also generates an API in the API Gateway that we can invoke with the above events as body mapping template in integration request of the method execution, just like the first example.&lt;/p&gt;

&lt;h3 id=&quot;serverless-framework&quot;&gt;Serverless Framework&lt;/h3&gt;

&lt;p&gt;While the above approach works as expected, it’s quite cumbersome to get your first function working. 
Especially since we didn’t write any actual code in the previous examples. 
Luckily the &lt;a href=&quot;http://serverless.com/&quot;&gt;Serverless Framework&lt;/a&gt; (formerly JAWS) is here to make our lives easier. 
Currently the Serverless Framework only supports AWS Lambda, but support for other IaaS providers is coming. 
A pull-request for &lt;a href=&quot;https://azure.microsoft.com/en-us/services/functions/&quot;&gt;Microsoft Azure&lt;/a&gt; &lt;a href=&quot;https://github.com/serverless/serverless/pull/1426&quot;&gt;already exists&lt;/a&gt; and other providers are also working on an implementation. 
Vendor-neutral FaaS would be a true game-changer!&lt;/p&gt;

&lt;p&gt;One problem with FaaS, is the (deliberate) mismatch between runtime unit and deploy unit. 
This is also true for other architectural patterns. 
It should be possible to deploy one specific function, but often functions will hang out in groups. 
I’d prefer to deploy a group of functions in one go, when it makes sense, eg. different CRUD operations on the same resource. 
This way, we benefit from the advantages of functions (scalability, cost, service independence, …) but also ease deployment. 
This is a key feature of the Serverless Framework.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/serverless/4.png&quot; alt=&quot;Serverless&quot; /&gt;&lt;/p&gt;

&lt;p&gt;On June 29th, Serverless V1.0-alpha1 was announced. 
New Alphas and Betas will be released on a regular basis. 
Currently the documentation can only be found in their &lt;a href=&quot;https://github.com/serverless/serverless/tree/v1.0/docs&quot;&gt;v1.0 branch on GitHub&lt;/a&gt;. Serverless V1.0 introduces the “Serverless Service” concept, which is a group of functions with their specific resource requirements. 
In essence Serverless V1.0 is a powerful and easy to use CLI to create, deploy and invoke functions. 
Serverless V1.0 uses &lt;a href=&quot;https://aws.amazon.com/cloudformation/&quot;&gt;AWS CloudFormation&lt;/a&gt; to create AWS resources. 
It uses the default &lt;a href=&quot;https://docs.aws.amazon.com/cli/latest/userguide/cli-chap-getting-started.html&quot;&gt;AWS profile&lt;/a&gt; for access to your AWS account. 
Creating, deploying and invoking a “Hello World” NodeJS function with Serverless is as easy as:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;serverless create --name cars --provider aws 
serverless deploy 
serverless invoke --function hello --path data.json
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;This generates the following lambda:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;'use strict'; 
module.exports.hello = (event, context, cb) =&amp;gt; cb(null, 
   { message: 'Go Serverless v1.0! Your function executed successfully!', event } 
); 
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;The current version of the Serverless Framework (unfortunately) doesn’t use the region from the AWS config, so you might need to look for your function in a different region.&lt;/p&gt;

&lt;p&gt;Adding an API Gateway endpoint, is also very easy and can be done by adding this http-event:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;events:
  - http:
       path: greet
       method: get
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;The actual URL can be found in the API Gateway in the stages section, as we saw before.&lt;/p&gt;

&lt;h1 id=&quot;part-2&quot;&gt;Part 2&lt;/h1&gt;

&lt;p&gt;In the first part of these article, I introduced the Serverless architectural style and focused on “market maker” &lt;a href=&quot;https://aws.amazon.com/lambda/details/&quot;&gt;AWS Lambda&lt;/a&gt; and on the &lt;a href=&quot;http://serverless.com/&quot;&gt;Serverless Framework&lt;/a&gt;. 
In this part, I want to focus on other Faas providers.&lt;/p&gt;

&lt;h2 id=&quot;auth0-webtask&quot;&gt;Auth0 Webtask&lt;/h2&gt;

&lt;p&gt;Compared to giants such as Amazon, Google, Microsoft and IBM, &lt;a href=&quot;https://auth0.com/&quot;&gt;Auth0&lt;/a&gt; is a rather small player. 
However acknowledging their experience with BaaS (Backend as a Service), FaaS is a logical choice for them. 
Currently &lt;a href=&quot;https://webtask.io/&quot;&gt;Webtask&lt;/a&gt; only supports NodeJS.&lt;/p&gt;

&lt;p&gt;The recommended way of using webtask is through the &lt;a href=&quot;https://webtask.io/cli&quot;&gt;wt command line interface&lt;/a&gt;. 
Auth0 has put the focus on easy of use. 
This is really visible by looking at their &lt;a href=&quot;https://webtask.io/docs/101&quot;&gt;30 second example&lt;/a&gt;. 
The &lt;strong&gt;wt create&lt;/strong&gt; command wil generate a function (a webtask) and will automatically return an HTTP endpoint, supporting URL query parameters. 
Every query parameter is available in your webtask in the form of context.data JavaScript object. 
With AWS Lambda you need to configure these in the AWS API Gateway, which is both tedious and time-consuming.&lt;/p&gt;

&lt;p&gt;A very interesting feature of Webtask is the availability of &lt;a href=&quot;https://webtask.io/docs/storage&quot;&gt;built-in storage&lt;/a&gt;.
Webtask code can store a single JSON document up to 500KB in size. 
This data can be stored with &lt;strong&gt;ctx.storage.set&lt;/strong&gt; and retrieved with &lt;strong&gt;ctx.storage.get&lt;/strong&gt;. 
While I don’t believe your function will often need this, it’s a very nice option.&lt;/p&gt;

&lt;p&gt;This small example (using &lt;a href=&quot;https://lodash.com/&quot;&gt;Lodash&lt;/a&gt;), shows a webtask using a query parameter and built-in storage.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;module.exports = function (ctx, cb) {
    var name = ctx.query.name;
 
    if(name) {
        ctx.storage.get(function(err, data){
            if(err) cb(err);
 
            data = data || [];
 
            if(_.indexOf(data, name) === -1 ){
                data.push(name);
 
                ctx.storage.set(data, function(err){
                    if(err){
                        cb(err);
                    } else {
                        cb(null, data);
                    }
                })
            } else {
                cb(null, data);
            }
        })
    } else {
        cb(null, &quot;422&quot;);
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Deploying this webtask, using the CLI:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Webtask created
 
You can access your webtask at the following url:
 
https://webtask.it.auth0.com/api/run/wt-&amp;amp;lt;your username&amp;amp;gt;-0/query_store?webtask_no_cache=1
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Another way to access your webtask is as a CRON job, using the &lt;strong&gt;wt cron&lt;/strong&gt; command or as a &lt;a href=&quot;https://webtask.io/docs/sample_github&quot;&gt;web hook&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Contrary to AWS Lambda, you don’t need to bundle the NodeJS modules you want to use. 
The list of supported modules is available &lt;a href=&quot;https://tehsis.github.io/webtaskio-canirequire/&quot;&gt;here&lt;/a&gt;. 
An option to bundle other modules is also &lt;a href=&quot;https://github.com/auth0/webtask-bundle&quot;&gt;available&lt;/a&gt;. 
Another difference is the use of query parameters.&lt;/p&gt;

&lt;p&gt;Not surprisingly, Webtask can be &lt;a href=&quot;https://webtask.io/docs/auth&quot;&gt;integrated with Auth0&lt;/a&gt; for authentication and authorization.&lt;/p&gt;

&lt;h2 id=&quot;google-cloud-functions&quot;&gt;Google Cloud Functions&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;https://cloud.google.com/functions/&quot;&gt;Google Cloud Functions&lt;/a&gt; (GCF) was released early 2016 and is currently in private alpha. 
Being in private alpha not only means that you specifically need to request access to use the GCF API, but also that you’re limited in sharing information. 
While this is obviously very unfortunate, it also means that Google is very serious about releasing a complete product. 
The activity in their (again private) Google Group proves this.&lt;/p&gt;

&lt;p&gt;Like its competitors, Cloud Functions can be triggered asynchronously by events (from Cloud Pub/Sub and Cloud Storage) or invoked synchronously via HTTPS. 
Currently GCF only supports NodeJS. 
Tutorials on common use-cases are available in &lt;a href=&quot;https://cloud.google.com/functions/docs/tutorials/&quot;&gt;their documentation&lt;/a&gt;. 
To build functions with GCF, you will first need to download and install the &lt;a href=&quot;https://cloud.google.com/sdk/docs/&quot;&gt;Google Cloud SDK&lt;/a&gt;. 
With the SDK installed, you can create your initial function &lt;em&gt;(replace datastore_gcf with your own staging bucket name)&lt;/em&gt;:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ gsutil mb gs://datastore_gcf
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;From the (very useful) &lt;a href=&quot;https://github.com/jasonpolites/gcf-recipes&quot;&gt;(unofficial) GCF recipes&lt;/a&gt; by &lt;a href=&quot;https://github.com/jasonpolites&quot;&gt;Jason Polites&lt;/a&gt; (Product Manager, GCP), we cloned the datastore example that will persist data to a &lt;a href=&quot;https://cloud.google.com/datastore/docs/concepts/overview&quot;&gt;Google Coud Datastore&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;From this repository, we deployed 2 functions ‘ds-get’ and ‘ds-set’ by executing:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ gcloud alpha functions deploy ds-set --bucket datastore_gcf --trigger-http --entry-point set
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;The names of the deployed functions, need to be exported in the Node.js module. These functions can be called with:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ gcloud alpha functions call ds-get --data '{&quot;kind&quot;: &quot;test&quot;, &quot;key&quot;: &quot;kid&quot;}'
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;or via the &lt;a href=&quot;https://console.cloud.google.com/functions&quot;&gt;Cloud Functions Console&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Your newly added data is also available in the &lt;a href=&quot;https://console.cloud.google.com/datastore/entities/&quot;&gt;Datastore Entities&lt;/a&gt; after selecting a project on the top. 
After executing a couple of functions, you can also find some metrics of your function (number of calls, execution time, …)&lt;/p&gt;

&lt;p&gt;Other arguments for the deploy command are listed in the &lt;a href=&quot;https://cloud.google.com/functions/docs/deploying/&quot;&gt;reference documentation&lt;/a&gt;. 
These steps are also available in the &lt;a href=&quot;https://console.cloud.google.com/home/&quot;&gt;Cloud Platform Console&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;After deployment, your webtrigger URL will be displayed similar to Webtask.&lt;/p&gt;

&lt;p&gt;Although much information on Google Cloud Functions is not (publicly) available yet, Google is well on its way to become a serious FaaS provider.&lt;/p&gt;

&lt;h2 id=&quot;azure-functions&quot;&gt;Azure Functions&lt;/h2&gt;

&lt;p&gt;Similar to Google Cloud Functions, &lt;a href=&quot;https://azure.microsoft.com/en-us/services/functions/&quot;&gt;Microsoft Azure Functions&lt;/a&gt; is currently in preview stage, meaning it’s not (yet) meant to be used in a production environment. 
Azure Cloud Functions (ACF) support a variety of languages such as NodeJS, C#, Python, and PHP.&lt;/p&gt;

&lt;p&gt;Today, it can be used for these common cases:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Events triggered by other Azure services&lt;/li&gt;
  &lt;li&gt;Events triggered by SaaS services (not limited to Microsoft)&lt;/li&gt;
  &lt;li&gt;Synchronous requests&lt;/li&gt;
  &lt;li&gt;WebHooks&lt;/li&gt;
  &lt;li&gt;Timer based processing (CRON)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;creating quite a large number of possibilities.&lt;/p&gt;

&lt;p&gt;Azure Functions are grouped in App Services. 
This is quite different from AWS Lambda, where the functions are organised independently. 
Hardware resources are allocated to an App Service and not directly to an Azure Function. 
It’s important to select a dynamic App Service if you’re aiming for “pay-per-execution”.&lt;/p&gt;

&lt;p&gt;When creating a new function, you can start from different templates. 
This can be compared to the blueprints from AWS Lambda. 
Currently 44 templates are available (but some are very similar). 
When selecting HttpTrigger for example, Azure Functions will generate a function that is able to use all query parameters passed to the function, similar to Webtask. 
&lt;a href=&quot;https://azure.microsoft.com/en-us/documentation/articles/functions-create-first-azure-function/&quot;&gt;This short video&lt;/a&gt; demonstrates this use case.&lt;/p&gt;

&lt;p&gt;In the example below, an Azure Cloud Function will store entities in a Storage Table when it receives an HTTP request:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;function.json&lt;/strong&gt;:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; &quot;bindings&quot;: [
    {
      &quot;type&quot;: &quot;httpTrigger&quot;,
      &quot;direction&quot;: &quot;in&quot;,
      &quot;name&quot;: &quot;req&quot;,
      &quot;methods&quot;: [
        &quot;post&quot;
      ],
      &quot;authLevel&quot;: &quot;function&quot;
    },
    {
      &quot;type&quot;: &quot;http&quot;,
      &quot;direction&quot;: &quot;out&quot;,
      &quot;name&quot;: &quot;res&quot;
    },
    {
      &quot;type&quot;: &quot;table&quot;,
      &quot;name&quot;: &quot;outTable&quot;,
      &quot;tableName&quot;: &quot;entities&quot;,
      &quot;partitionKey&quot;: &quot;functions&quot;,
      &quot;rowKey&quot;: &quot;%rand-guid%&quot;,
      &quot;connection&quot;: &quot;YOUR_STORAGE&quot;,
      &quot;direction&quot;: &quot;out&quot;
    }
  ],
  &quot;disabled&quot;: false
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;index.js&lt;/strong&gt;:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    var statusCode = 400;
    var responseBody = &quot;Invalid request object&quot;;
 
    if (typeof req.body != 'undefined' &amp;amp;amp;&amp;amp;amp; typeof req.body == 'object') {
        statusCode = 201;
        context.bindings.outTable = req.body;
        responseBody = &quot;Table Storage Created&quot;;
    }
 
    context.res = {
        status: statusCode,
        body: responseBody
    };
 
    context.done();
};
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;To retrieve the added entities:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;functions.json&lt;/strong&gt;:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  &quot;bindings&quot;: [
    {
      &quot;type&quot;: &quot;httpTrigger&quot;,
      &quot;direction&quot;: &quot;in&quot;,
      &quot;name&quot;: &quot;req&quot;,
      &quot;methods&quot;: [
        &quot;get&quot;
      ],
      &quot;authLevel&quot;: &quot;function&quot;
    },
    {
      &quot;type&quot;: &quot;http&quot;,
      &quot;direction&quot;: &quot;out&quot;,
      &quot;name&quot;: &quot;res&quot;
    },
    {
      &quot;type&quot;: &quot;table&quot;,
      &quot;name&quot;: &quot;inTable&quot;,
      &quot;tableName&quot;: &quot;entities&quot;,
      &quot;connection&quot;: &quot;YOUR_STORAGE&quot;,
      &quot;direction&quot;: &quot;in&quot;
    }
  ],
  &quot;disabled&quot;: false
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;index.js&lt;/strong&gt;:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    context.log(&quot;Retrieved records:&quot;, intable);
    context.res = {
        status: 200,
        body: intable
    };
    context.done();
};
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;/img/serverless/5.png&quot; alt=&quot;Serverless&quot; /&gt;&lt;/p&gt;

&lt;p&gt;What immediately struck me was the quality of their documentation (videos, tours, quickstarts, templates, …) and the user experience from the &lt;a href=&quot;https://azure.microsoft.com/en-us/features/azure-portal/&quot;&gt;Azure Portal&lt;/a&gt;. 
The portal can be a little slow sometimes, but the experience is miles ahead of what Amazon and Google are offering. 
Azure Functions is &lt;a href=&quot;https://azure.microsoft.com/en-us/documentation/articles/functions-reference/&quot;&gt;open source and available on GitHub&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Azure Functions will soon be supported by the &lt;a href=&quot;https://github.com/serverless/serverless/pull/1547&quot;&gt;Serverless Framework&lt;/a&gt;, which is a big step towards vendor-neutral FaaS.&lt;/p&gt;

&lt;h2 id=&quot;ibm-bluemix-openwhisk&quot;&gt;IBM Bluemix OpenWhisk&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;https://developer.ibm.com/openwhisk/&quot;&gt;Bluemix OpenWhisk&lt;/a&gt; is also an &lt;a href=&quot;https://github.com/openwhisk/openwhisk&quot;&gt;open source&lt;/a&gt; service and currently supports NodeJS and Swift. 
Contrary to other FaaS providers, IBM emphasises on container integration. 
When an event or an API call invokes an action, OpenWhisk creates a container to run the action in a runtime appropriate to the programming language used. 
You can even create Docker functions (called actions in OpenWhisk) allowing you to build in any language. 
OpenWhisk can also run locally on your own hardware, which no other provider currently offers. 
IBM is very open about this and even provides &lt;a href=&quot;https://github.com/openwhisk/openwhisk/blob/master/README.md&quot;&gt;guidelines&lt;/a&gt; on how this can be achieved.&lt;/p&gt;

&lt;p&gt;As expected, the documentation has a &lt;a href=&quot;https://console.ng.bluemix.net/docs/openwhisk/index.html&quot;&gt;getting started&lt;/a&gt; guide to build and run a Hello World action. 
While working with the CLI works as advertised, it quickly becomes quite cumbersome, especially when integrating with other &lt;a href=&quot;https://console.ng.bluemix.net/docs/openwhisk/openwhisk_catalog.html&quot;&gt;Bluemix services&lt;/a&gt;. 
After executing your first OpenWhisk function, you can see some metrics in the (pretty) &lt;a href=&quot;https://new-console.ng.bluemix.net/openwhisk/dashboard&quot;&gt;OpenWhisk dashboard&lt;/a&gt;. 
The OpenWhisk dashboard will show all invoked actions, also from actions you didn’t implement yourself. 
For example when using &lt;a href=&quot;https://console.ng.bluemix.net/docs/openwhisk/openwhisk_packages.html&quot;&gt;existing packages&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/serverless/6.png&quot; alt=&quot;Serverless&quot; /&gt;&lt;/p&gt;

&lt;p&gt;What’s even more impressive is the &lt;a href=&quot;https://new-console.ng.bluemix.net/openwhisk/editor&quot;&gt;Openwhisk Editor&lt;/a&gt;. 
This editor only lists the actions you created yourself.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/serverless/7.png&quot; alt=&quot;Serverless&quot; /&gt;&lt;/p&gt;

&lt;p&gt;As you can see from the screenshot, you immediately get links to the REST Endpoint.&lt;/p&gt;

&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;Currently it’s too soon to draw any conclusions. 
These services are constantly changing. 
What is obvious, is that all major cloud providers want to make sure that they don’t miss the FaaS opportunity. 
Cloud providers create value by integrating FaaS services with their other offerings. 
This confirms the value of a Serverless Cloud. 
The current FaaS solutions have a lot of similar characteristics and choosing one, will likely depend on what other services you already use (or want to use) from a certain provider. 
It’s important to know the environment your FaaS code lives in and the services available to it. 
In this phase available documentation also is crucial.&lt;/p&gt;

&lt;p&gt;Obviously, this high-level introduction doesn’t list all the differences or similarities, but it offers a nice starting point to experience the FaaS (r)evolution first-hand.&lt;/p&gt;

&lt;h1 id=&quot;part-3&quot;&gt;Part 3&lt;/h1&gt;

&lt;p&gt;In the first part of this article, I introduced the Serverless architectural style. 
In the second part, I compared all major serverless providers. 
In this third and last part, I would like to look at serverless as an enabler of &lt;a href=&quot;http://www.slideshare.net/BartBlommaerts/the-collaborative-economy-61528579&quot;&gt;collaborative economy&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;collaborative-economy&quot;&gt;Collaborative Economy&lt;/h2&gt;

&lt;p&gt;What is collaborative ecomomy?&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;a href=&quot;https://twitter.com/benitamatofska&quot;&gt;Benita Matofska&lt;/a&gt;: The Sharing Economy is a socio-economic ecosystem built around the sharing of human, physical and intellectual resources.
It includes the shared creation, production, distribution, trade and consumption of goods and services by different people and organisations.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;The last part of Benita’s quote: &lt;em&gt;shared creation, production .. of services by different people and organisations&lt;/em&gt; makes a very nice use-case for the serverless style of building applications.&lt;/p&gt;

&lt;h3 id=&quot;your-data&quot;&gt;Your data&lt;/h3&gt;

&lt;p&gt;In this day and age, all companies have become IT companies, meaning a lot of data is gathered and stored somewhere. 
Often the usage of the available data changes over time. 
If data is not used for the benefit of the enterprise or its employees, does it still hold value? 
Wouldn’t it be great if we could turn cost into profit?&lt;/p&gt;

&lt;p&gt;Thanks to its cost model (pay per execution), its focus on scalability (no risk of overprovisioning) and resilience, serverless enables companies to experiment with exposing their data:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Offering an API for others to consume&lt;/li&gt;
  &lt;li&gt;Enriching existing API’s with their data&lt;/li&gt;
  &lt;li&gt;…&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;your-ideas&quot;&gt;Your ideas&lt;/h3&gt;

&lt;p&gt;Serverless also makes a lot of sense for companies that don’t want to expose their data, but have great or new ideas on how to use others data:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Combining data from multiple providers&lt;/li&gt;
  &lt;li&gt;Filtering and transforming data&lt;/li&gt;
  &lt;li&gt;New business cases beyond the scope of the original API&lt;/li&gt;
  &lt;li&gt;…&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;example&quot;&gt;Example&lt;/h3&gt;
&lt;p&gt;I implemented a small and simple application that will consume data from different serverless cloud providers. 
Every “hop” in the system will parse its input and add some new data.&lt;/p&gt;

&lt;h4 id=&quot;component-diagram&quot;&gt;Component diagram&lt;/h4&gt;

&lt;p&gt;&lt;img src=&quot;/img/serverless/8.png&quot; alt=&quot;Serverless&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;description&quot;&gt;Description&lt;/h4&gt;
&lt;p&gt;Any client can post a JSON to the first function, made with &lt;a href=&quot;https://webtask.io/&quot;&gt;Auth0 webtask&lt;/a&gt;. 
The body of the post request is simple:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;temp&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;42&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;The WebTask will parse that input, add some input of its own and POST request to an &lt;a href=&quot;http://www.ibm.com/cloud-computing/bluemix/openwhisk/&quot;&gt;IBM OpenWhisk&lt;/a&gt; action. 
The body of this POST request:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;hops&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
      &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;provider&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Auth 0 Webtask&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
      &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;start&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;2016-08-24T20:32:03.629Z&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
      &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;temperature&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;42&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
      &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;stop&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;2016-08-24T20:32:03.629Z&quot;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;To continue the chain, IBM OpenWhisk will POST the parsed JSON to a function on the &lt;a href=&quot;https://aws.amazon.com/lambda/details/&quot;&gt;AWS Lambda&lt;/a&gt; platform after adding a new “hop”:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;hops&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
      &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;provider&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Auth 0 Webtask&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
      &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;start&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;2016-08-26T18:38:25.021Z&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
      &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;temperature&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;44&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
      &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;stop&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;2016-08-26T18:38:25.021Z&quot;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
      &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;provider&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;IBM OpenWhisk&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
      &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;start&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;2016-08-26T18:38:35.024Z&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
      &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;temperature&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;42&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
      &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;stop&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;2016-08-26T18:38:35.024Z&quot;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;The Lambda, created with &lt;a href=&quot;https://serverless.com/&quot;&gt;Serverless V1.0 Beta 2&lt;/a&gt; will parse the input again and create items in an &lt;a href=&quot;http://aws.amazon.com/dynamodb&quot;&gt;AWS DynamoDB&lt;/a&gt;:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/serverless/9.png&quot; alt=&quot;Serverless&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The AWS DynamoDB table will stream events to another AWS Lambda that will log the content of the event to the logs of AWS CloudWatch:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/serverless/10.png&quot; alt=&quot;Serverless&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The source code of all these components is available on &lt;a href=&quot;https://github.com/bart-blommaerts/serverless-demo&quot;&gt;GitHub&lt;/a&gt;.&lt;/p&gt;

&lt;h4 id=&quot;best-practice&quot;&gt;Best practice&lt;/h4&gt;

&lt;p&gt;Obviously I wouldn’t recommend anyone to use a different cloud provider for every function. 
Choosing the right one will depend on your specific needs, goals and current cloud landscape. 
In previous parts of this article, you may find some tips on how to make a reasoned choice.&lt;/p&gt;

&lt;h3 id=&quot;final-note&quot;&gt;Final note&lt;/h3&gt;

&lt;p&gt;This article was originally posted in three parts on the &lt;a href=&quot;https://jaxlondon.com/the-serverless-cloud-part-1/&quot;&gt;JAX London blog&lt;/a&gt; and is also available in &lt;a href=&quot;https://jaxenter.de/serverless-cloud-teil-1-48379&quot;&gt;German&lt;/a&gt;.&lt;/p&gt;

</description>
        <pubDate>Sat, 12 Nov 2016 00:00:00 +0000</pubDate>
        <link>https://ordina-jworks.github.io/cloud/2016/11/12/TheServerlessCloud.html</link>
        <guid isPermaLink="true">https://ordina-jworks.github.io/cloud/2016/11/12/TheServerlessCloud.html</guid>
        
        <category>Cloud</category>
        
        <category>Serverless</category>
        
        <category>AWS</category>
        
        <category>Lambda</category>
        
        <category>Azure</category>
        
        <category>Google Cloud Platform</category>
        
        <category>IBM Bluemix</category>
        
        <category>OpenWhisk</category>
        
        <category>Webtask</category>
        
        <category>Collaborative Economy</category>
        
        
        <category>Cloud</category>
        
      </item>
    
      <item>
        <title>Kickstarter project 2016</title>
        <description>&lt;blockquote&gt;
  &lt;p&gt;On August 1&lt;sup&gt;‘st&lt;/sup&gt; it was D-day for all the kickstarters that had recently joined Ordina. A batch of talented new people were ready to embark on a new adventure. This year around fifty people joined Ordina and participated in the Kickstarter Project. The JWorks kickstarter group consisted of seven people, all of which were eager to get started. Six people joined the JWorks unit and one joined the Security unit. The purpose of the two month long kickstarter project is to broaden the knowledge of and prepare the kickstarters for their first project.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;kickstarter-project-2016&quot;&gt;Kickstarter project 2016&lt;/h1&gt;

&lt;h2 id=&quot;first-impressions&quot;&gt;First impressions&lt;/h2&gt;

&lt;p&gt;&lt;q&gt;You never get a second chance to make a first impression.&lt;/q&gt;
&lt;br /&gt;
– &lt;cite&gt;Harlan Hogan&lt;/cite&gt;&lt;/p&gt;

&lt;p&gt;And boy Ordina did a pretty good job!&lt;/p&gt;

&lt;p&gt;The reception on the first day was really great and pretty informal.
First off the kickstarters received a tour of the company.
They introduced themselves and got to know eachother in a pretty playful way.
FINALLY the moment had arrived that everybody was waiting for !
The kickstarters received their highly anticipated company car and laptop.&lt;/p&gt;

&lt;p&gt;The overal atmosphere is pretty loose, you can ask anyone anything and you can talk to everybody.&lt;/p&gt;

&lt;p&gt;After a few days the kickstarters also got the chance to go on a teambuilding day in Mechelen.
During the course of this day, they had to work together as a team to complete some questions and games.
The winners were rewarded with a cup. This enabled them to learn how to communicate in a team and under stress, because some of the tests had to be completed within an certain amount of time.&lt;/p&gt;

&lt;p&gt;Most of the kickstarters already had the chance to go to one of the Ordina events like JOIN or CC meetings, where they networked with lots of interesting people.&lt;/p&gt;

&lt;h2 id=&quot;august---learning&quot;&gt;August - Learning&lt;/h2&gt;

&lt;p&gt;The focus was primarily on learning during the first month of the Kickstarters project.
The first few days the kickstarters had to improve their softskills by learning how to be more assertive towards the client when necessary.
They also learned to introduce themselves properly with the emphasis on their qualities and strengths, to ensure they make a good first impression of themselves when going to the client.&lt;/p&gt;

&lt;p&gt;The kickstarters were brought up to date with the preferred technologies, editors and best practices used by JWorks.
During the first month they received different courses in which they could improve their technical skills about:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;backend
    &lt;ul&gt;
      &lt;li&gt;Java (7 &amp;amp; 8) + JavaEE&lt;/li&gt;
      &lt;li&gt;Spring&lt;/li&gt;
      &lt;li&gt;JPA&lt;/li&gt;
      &lt;li&gt;Webservices (REST &amp;amp; SOAP)&lt;/li&gt;
      &lt;li&gt;MongoDB&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;frontend
    &lt;ul&gt;
      &lt;li&gt;HTML &amp;amp; CSS&lt;/li&gt;
      &lt;li&gt;Javascript &amp;amp; Typescript&lt;/li&gt;
      &lt;li&gt;Angular&lt;/li&gt;
      &lt;li&gt;Ionic&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;These courses were given by the JWorks unit who tried to teach the kickstarters a much as possible with theoretical material and some exercises afterwards.
Unfortunately, these technical skills aren’t enough to survive in the forever changing IT world.
This is why some extra help was provided in the form of books and courses about how to write clean code, how to work agile and learning how to work in a team while understanding and using the SCRUM principles.&lt;/p&gt;

&lt;p&gt;By paying attention to technical development with the necessary certification processes and also focusing on the development of soft skills like communication, advising and collaboration,
Ordina commits to the personal development of these kickstarters.&lt;/p&gt;

&lt;h2 id=&quot;september---dev-case&quot;&gt;September - Dev-case&lt;/h2&gt;

&lt;p&gt;The focus during the second month was on the implementation of this year’s dev-case.
Although they still had to follow a few courses along the way, like the basic priciples of security, GIT and learning how to use MongoDB.&lt;/p&gt;

&lt;h3 id=&quot;sensymcsenseface-was-born&quot;&gt;SensyMcSenseFace was born&lt;/h3&gt;
&lt;p&gt;– &lt;cite&gt;Chosen by popular vote, who would have guessed it…&lt;/cite&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;The kickstarters already had learned how to write clean code and how to do this in the best possible way.
The purpose of the SensyMcSenseFace project was to give the kickstarters a use case where they could develop an end-to-end IoT solution, in which they could test and use their newly acquired skills.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/kickstarters/2016/IoT.jpg&quot; alt=&quot;SensyMcSenseFaceProject&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;what-did-the-client-request&quot;&gt;What did the client request&lt;/h3&gt;

&lt;p&gt;The kickstarters were given the task to build an application that accepts incoming data, while being able to process this data and output it in a more user friendly way.&lt;/p&gt;

&lt;p&gt;The data would be sent by three different sensors:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Temperature sensor&lt;/li&gt;
  &lt;li&gt;Humidity sensor&lt;/li&gt;
  &lt;li&gt;Motion sensor&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;These sensors send some data every few seconds to the backend, the backend then processes this data and sends it back to the frontend.
Here the frontend developers made sure that all the data has been received and outputted in the correct way.&lt;/p&gt;

&lt;p&gt;The following picture depicts the two meeting rooms that are equipped with three different sensors, which send their data back to the application’s backend.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/kickstarters/2016/floorplan.jpg&quot; alt=&quot;Floor Plan&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Each meeting room equipped with the sensors, which have their values read by an Arduino that then sends these across the Proximus LoRa network to the backend. For the initial stages and testing the LoRa part was omitted and a simple node server instance was used to relay the sensor values to the actual backend.&lt;/p&gt;

&lt;p&gt;This way, the client (Ordina) could figure out when they are using excessive power.
For example people leaving the TV on for too long inside of the meeting rooms.&lt;/p&gt;

&lt;h3 id=&quot;used-technologies---sofware&quot;&gt;Used technologies - sofware&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;backend
    &lt;ul&gt;
      &lt;li&gt;Maven&lt;/li&gt;
      &lt;li&gt;Spring&lt;/li&gt;
      &lt;li&gt;Spring Boot&lt;/li&gt;
      &lt;li&gt;MongoDB&lt;/li&gt;
      &lt;li&gt;Mockito&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;frontend
    &lt;ul&gt;
      &lt;li&gt;Angular 2&lt;/li&gt;
      &lt;li&gt;Angular Material 2&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;extra
    &lt;ul&gt;
      &lt;li&gt;Waffle&lt;/li&gt;
      &lt;li&gt;Cloudfoundry&lt;/li&gt;
      &lt;li&gt;GitHub&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;process-of-the-project&quot;&gt;Process of the project&lt;/h3&gt;

&lt;p&gt;The first week went pretty well, they divided themselves up into two groups.
One group for the frontend and the other one for the backend.
At first they started to create different user stories for their SCRUM board.
Using the newly acquired scrum techniques during the first month.
The kickstarters had to work in four short sprints of one week. During the first sprint they also decided to change their real life SCRUM board into an online version using Waffle.
This software would track the pull requests and merges automatically from Github and change the board accordingly.
Continuous Integration was pretty important during the course of the project.
This way, whenever they made changes to the code and made a pull request to Github that failed to build, they had to fix their code before they could continue.
Once the build on codeship succeeded and the pull request was merged. The main development branch and master branch would have their changes (if any) deployed to their Cloudfoundry instance.&lt;/p&gt;

&lt;p&gt;The process for the backend was pretty simple.
They started out with around five people, so some of them started to pair program while others started to program on their own.
But, with paying attention to the SCRUM principles and how to write clean code.
Their first job was to start with the basic implementations of the sensor, room and notifications classes and writing the JUnit and Mockito tests.
While the backend was pretty straight forward and relatively easy to begin with, the frontend team were confronted with some problems.
The team consisted of only two people who had to tackle a lot of problems with the use of Angular 2 which was still in Beta at the time.
Also the combination with the other frameworks wasn’t quite that easy to work with.&lt;/p&gt;

&lt;p&gt;Every morning the team did a stand up meeting where they would discuss their changes in eachothers code and what they were going to do next.
During these four weeks they tried to work in these short sprints but after a week or two it became clear this wouldn’t be an easy task.
A few team members already had left the group because they were assigned to projects, which messed up their sprints completely.&lt;/p&gt;

&lt;p&gt;During the first two weeks the backend team started with using Spring Data JPA, but soon figured out Spring Data MongoDB was the better alternative because of the large amount of data being pumped into the DB.
A lot of time of went into providing REST documentation that covers all the different calls handled by the application.
This documentation was created with MockMvc tests, which create code snippets that were easy to use.&lt;/p&gt;

&lt;p&gt;On the frontend side they didn’t have test cases yet, but nobody in the entire team had ever written frontend tests before.
Which caused a little bit of a delay, also the webpages didn’t seem to be responsive at all.
Luckily there were some online tutorials available on mocking and writing frontend tests.
The responsiveness issue was sovled by using their own components and CSS code instead of using material design.&lt;/p&gt;

&lt;p&gt;When starting their two final weeks there were only three people left who were able to fully commit to the dev-case.
During the last week the kickstarters also had to prepare and give a proper introduction to the management of Ordina.
Showing off their newly learned presentation and introduction techniques.&lt;/p&gt;

&lt;p&gt;At the very end the core of the application was finished.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;You are able to watch an overview of the rooms&lt;/li&gt;
  &lt;li&gt;You are able to check if a room is occupied or available&lt;/li&gt;
  &lt;li&gt;You are able to check which sensors are in a room and check their last history&lt;/li&gt;
  &lt;li&gt;You are able to check the sensor history between two timestamps&lt;/li&gt;
  &lt;li&gt;You are able to get notifications on your cellphone when certain values are exceeded&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;possible-future-changes&quot;&gt;possible future changes&lt;/h3&gt;

&lt;p&gt;Because there wasn’t enough time to completely finish the project, this project can still evolve in a lot of ways.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Later on it could be possible to add roles or users.&lt;/li&gt;
  &lt;li&gt;Make adding sensors or rooms more user friendly.&lt;/li&gt;
  &lt;li&gt;Add predictions to the applications for every room.&lt;/li&gt;
  &lt;li&gt;Add user management with users and roles&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;lessons-learned-during-the-kickstarters-project&quot;&gt;Lessons learned during the Kickstarters project&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;How to be more confident&lt;/li&gt;
  &lt;li&gt;How to introduce yourself in a professional way&lt;/li&gt;
  &lt;li&gt;How to be more assertive&lt;/li&gt;
  &lt;li&gt;You have to keep an eye out for possible changes in your code that encourage clean code&lt;/li&gt;
  &lt;li&gt;How to work better and agile in a team and how to use SCRUM principles&lt;/li&gt;
  &lt;li&gt;Pitfalls and difficulties when using and combining new technologies&lt;/li&gt;
  &lt;li&gt;How to write proper tests (JUnit, Mockito, MvcTests)&lt;/li&gt;
  &lt;li&gt;How to write proper REST documentation&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;the-new-jworks-colleagues&quot;&gt;The new JWorks colleagues&lt;/h2&gt;

&lt;p&gt;&lt;img class=&quot;p-image float-image&quot; width=&quot;100&quot; alt=&quot;Axel Bergmans&quot; src=&quot;/img/kickstarters/2016/axel-bergmans.jpg&quot; /&gt;
&lt;img class=&quot;p-image float-image&quot; width=&quot;100&quot; alt=&quot;Matthias Caryn&quot; src=&quot;/img/kickstarters/2016/matthias-caryn.jpg&quot; /&gt;
&lt;img class=&quot;p-image float-image&quot; width=&quot;100&quot; alt=&quot;Madi Dudaeva&quot; src=&quot;/img/kickstarters/2016/madi-dudaeva.jpg&quot; /&gt;
&lt;img class=&quot;p-image float-image&quot; width=&quot;100&quot; alt=&quot;Christophe Theyssen&quot; src=&quot;/img/kickstarters/2016/christophe-theyssen.jpg&quot; /&gt;
&lt;img class=&quot;p-image float-image&quot; width=&quot;100&quot; alt=&quot;Ines Verstappen&quot; src=&quot;/img/kickstarters/2016/ines-vanstappen.jpg&quot; /&gt;
&lt;img class=&quot;p-image float-image&quot; width=&quot;100&quot; alt=&quot;Tim Verté&quot; src=&quot;/img/kickstarters/2016/tim-verte.jpg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;
</description>
        <pubDate>Mon, 31 Oct 2016 00:00:00 +0000</pubDate>
        <link>https://ordina-jworks.github.io/kickstarters/2016/10/31/Kickstarters-Project.html</link>
        <guid isPermaLink="true">https://ordina-jworks.github.io/kickstarters/2016/10/31/Kickstarters-Project.html</guid>
        
        <category>Spring</category>
        
        <category>Angular2</category>
        
        <category>Unit Test</category>
        
        <category>Postman</category>
        
        <category>Spring Boot</category>
        
        <category>Spring REST Docs</category>
        
        
        <category>Kickstarters</category>
        
      </item>
    
      <item>
        <title>Percona Live Amsterdam 2016</title>
        <description>&lt;p&gt;&lt;a href=&quot;https://www.percona.com/live/plam16/&quot;&gt;Percona Live&lt;/a&gt; Open Source Database Conference 2016, Amsterdam&lt;/p&gt;

&lt;p style=&quot;text-align: center;&quot;&gt;
  &lt;img style=&quot;max-width: 640px;&quot; alt=&quot;Percona Live Amsterdam Logo&quot; src=&quot;/img/2016-10-16-Percona-Live/PLAM-16-01.png&quot; /&gt;
&lt;/p&gt;

&lt;p&gt;It was only three weeks before the conference, that I coincidentally discovered (and by Googling) that Percona was organizing one of the biggest Open Source Databases conferences in Amsterdam, Percona Live Europe.
Until then I had never heard of Percona.
Shame on me! But, Percona is mostly known in the US and according to db-engine.com it’s takes the 47th  place on the popularity list of Relational Databases, and the 97th spot if you consider all database systems.&lt;/p&gt;

&lt;p&gt;Yet, Percona is celebrating its 10th anniversary this year and among it’s more than 3000 customers worldwide it can count well-known brands like Cisco Systems, Time Warner Cable, Alcatent-Lucent, Groupon, BBC, Flickr, … among  it’s customers.
It was at the conference that I uncovered that Percona Server is in fact a fork of the MySQL open source database, just like the more popular fork MariaDB.
Percona presents itself on their website as the only company that delivers enterprise-class solutions for both MySQL and MongoDB across traditional and cloud-based platforms.&lt;/p&gt;

&lt;p&gt;So it was obvious that the focus of the three-day conference was on MySQL and MongoDB.
With 16 tutorials on Monday, 48 sessions on Tuesday and even 64 sessions on Wednesday the line-up was impressive.
Most of the sessions covered MySQL, MongoDB and PostgreSQL topics but other open source databases like ElasticSearch, Redis, RethinkDB, Clickhouse,… were also discussed.
Even with two people of JWorks attending the Conference, picking the right sessions was difficult and the &lt;a href=&quot;https://en.wikipedia.org/wiki/Fear_of_missing_out&quot;&gt;FoMO syndrome&lt;/a&gt; was clearly around the corner.&lt;/p&gt;

&lt;p&gt;While the conference mainly had a technical focus (sometimes in-depth), with subjects as analytics, architecture and design, security, operations, scalability and performance, I was pleased that these sessions were alternated with customer stories.
Eventually it is always interesting to see real life uses cases and big names like Facebook, Uber, Dropbox and Booking.com talking about the open source databases they use, and especially how they use them.
Facebook was represented by 10 of its employees involved in 7 talks.
To pick some : &lt;a href=&quot;https://www.percona.com/live/plam16/sessions/one-system-fit-them-all-shared-mysql-hosting-facebook&quot;&gt;Shared MySQL hosting at Facebook&lt;/a&gt;, &lt;a href=&quot;https://www.percona.com/live/plam16/sessions/massive-schema-changes-facebook&quot;&gt;Massive Schema changes in Facebook&lt;/a&gt;, &lt;a href=&quot;https://www.percona.com/live/plam16/sessions/myrocks-deep-dive-flash-optimized-lsm-database-mysql-and-its-use-case-facebook&quot;&gt;MyRocks Deep Dive: Flash Optimized LSM Database for MySQL, and its Use Case at Facebook&lt;/a&gt;, &lt;a href=&quot;https://www.percona.com/live/plam16/sessions/everyday-we%E2%80%99re-shuffling-%E2%80%94-online-shard-migration-facebook&quot;&gt;Online Shard Migration at Facebook&lt;/a&gt;,…&lt;/p&gt;

&lt;p&gt;The conference made it also clear that interest in Open Source Databases continues to grow.
More and more companies are looking to replace their proprietary databases to open source alternatives.
The reasons for that are clear, open source databases maturity have risen to the level of the proprietary databases and some of them have even gone beyond that.
And al of that, without the hefty price tag.  Top Internet applications have embraced open source databases a long time ago, and now traditional enterprises are catching up to.&lt;/p&gt;

&lt;p&gt;So me and my colleague Chris De Bruyne both returned with a backpack full of very useful information that we like to share with you in the coming months.
We will definitely try out a lot of stuff, like the different open source monitoring tools for MySQL and MongoDB.&lt;/p&gt;

&lt;p&gt;The JWorks DBA / NoSQL competence center also advocates the use of open source alternatives when appropriate, and this conference perfectly matches with our ambitions.
So we already reserved 25th - 27th of September 2017 in our agendas for the next Percona Live Europe in Dublin.&lt;/p&gt;
</description>
        <pubDate>Mon, 10 Oct 2016 00:00:00 +0000</pubDate>
        <link>https://ordina-jworks.github.io/conferences/2016/10/10/Percona-Live-Amsterdam-2016.html</link>
        <guid isPermaLink="true">https://ordina-jworks.github.io/conferences/2016/10/10/Percona-Live-Amsterdam-2016.html</guid>
        
        <category>Percona Live</category>
        
        <category>MySql</category>
        
        <category>MongoDB</category>
        
        <category>MariaDB</category>
        
        <category>DBA</category>
        
        <category>PostgreSQL</category>
        
        
        <category>Conferences</category>
        
      </item>
    
      <item>
        <title>JOIN 2016</title>
        <description>&lt;blockquote&gt;
  &lt;p&gt;Next week, on the 5th of October 2016, the JWorks Business Unit of Ordina will organize its yearly JOIN event. The purpose of this event is to share knowledge between colleagues and fellow Java, JVM, JavaScript, Cloud and DevOps enthusiasts. Last year, a total of 83 attendees visited Ordina Belgium’s headquarters in Mechelen to learn and talk about the hottest technology trends and developments.
This year we expect to have more than 100 attendees, and what’s most exciting is that the event is completely free of charge and everyone is invited. Food and drinks are provided (including a barbecue).&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;join-2016-schedule&quot;&gt;JOIN 2016 Schedule&lt;/h3&gt;

&lt;p style=&quot;text-align: center;&quot;&gt;
  &lt;img alt=&quot;JOIN 2016 Schedule&quot; src=&quot;/img/JOIN-schedule-small.jpg&quot; /&gt;
&lt;/p&gt;

&lt;p&gt;Here are some of the highlights of the day:&lt;/p&gt;

&lt;h3 id=&quot;am---12am---docker-for-java-developers---arun-gupta&quot;&gt;10AM - 12AM - Docker for Java Developers - Arun Gupta&lt;/h3&gt;

&lt;p&gt;&lt;img class=&quot;float-image p-image&quot; src=&quot;/img/arun-gupta.png&quot; alt=&quot;Arun Gupta&quot; style=&quot;width: 100px&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Arun has been an avid Docker user for many years and is also one of the Docker Captains, among being a Java Champion and JUG leader.
He will bring us a very informative talk about the current state of Docker and how Java Developers can get started with Docker in no time.&lt;/p&gt;

&lt;p&gt;We’re very much looking forward to this one!&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;During another talk he will talk about &lt;strong&gt;Couchbase&lt;/strong&gt;, the product company he’s working for at the moment.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;More information about Arun in his &lt;a href=&quot;https://blog.docker.com/2016/03/docker-community-spotlight-arun-gupta/&quot;&gt;Docker Community Spotlight&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&quot;pm---6pm---the-google-cloud-platform---koen-maes&quot;&gt;5PM - 6PM - The Google Cloud Platform - Koen Maes&lt;/h3&gt;

&lt;p&gt;&lt;img class=&quot;float-image p-image&quot; src=&quot;/img/koen-maes.jpg&quot; alt=&quot;Koen Maes&quot; style=&quot;width: 100px&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Koen Maes provides expert advice and development services for Google Cloud Platform and related products.
He is a Google Cloud Platform Authorized Trainer &amp;amp; partner and has been working in the software industry since the early nineties and with web/Internet technology since its inception.
He designed key applications for several large corporations as well as running a handful of startups of his own, some more successful than others.
Since his first encounters with AppEngine in 2009, he never looked back and has been specializing in Google Cloud Platform ever since.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;We are currently working for one of our customers on a large scale greenfield microservices system in the Google Cloud Platform, so this will be especially interesting for us.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;pm---7pm---reactive-programming---stephane-maldini&quot;&gt;6PM - 7PM - Reactive Programming - Stephane Maldini&lt;/h3&gt;

&lt;p&gt;&lt;img class=&quot;float-image p-image&quot; src=&quot;/img/stephane-maldini.jpeg&quot; alt=&quot;Stephane Maldini&quot; style=&quot;width: 100px&quot; /&gt;&lt;/p&gt;

&lt;p&gt;A multi-tasker eating tech 24/7, Stephane is interested in cloud computing, data science and messaging.
Leading the Reactor Project, Stephane Maldini is on a mission to help developers create reactive and efficient architectures on the JVM and beyond.
He is also one of the main contributors for Reactive support in the upcoming Spring 5 framework.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;David Karnok, RxJava project lead, identifies the Reactor project as the new standard for reactive applications in the Java world.
Most of the developers in our JWorks unit are using Spring (as opposed to JEE), so this talk is going to be &lt;strong&gt;very&lt;/strong&gt; interesting.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;pm---8pm---typescript-enjoying-large-scale-browser-development---joost-de-vries&quot;&gt;7PM - 8PM - Typescript: enjoying large scale browser development - Joost De Vries&lt;/h3&gt;

&lt;p&gt;&lt;img class=&quot;float-image p-image&quot; src=&quot;/img/joost-devries.jpg&quot; alt=&quot;Joost De Vries&quot; style=&quot;width: 100px&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Joost De Vries is one of our Dutch colleagues at &lt;a href=&quot;https://www.codestar.nl/#center&quot;&gt;Codestar&lt;/a&gt;. He will talk about Typescript and how it enables development of large scale front end applications.&lt;/p&gt;

&lt;p&gt;You can find him on &lt;a href=&quot;https://twitter.com/jouke&quot;&gt;Twitter&lt;/a&gt; and &lt;a href=&quot;https://github.com/joost-de-vries&quot;&gt;Github&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&quot;food&quot;&gt;Food&lt;/h3&gt;

&lt;p style=&quot;text-align: center;&quot;&gt;
  &lt;img alt=&quot;JOIN 2016 Schedule&quot; src=&quot;/img/bbq-food-drinks.jpg&quot; /&gt;
&lt;/p&gt;

&lt;p&gt;We have foreseen &lt;strong&gt;food and drinks&lt;/strong&gt; during the conference and we will &lt;strong&gt;end the night with something special&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;We hope and believe it will make everyone &lt;strong&gt;very&lt;/strong&gt; happy! Another reason to JOIN us &lt;a href=&quot;https://www.ordina.be&quot;&gt;@Ordina&lt;/a&gt;, the 5th of October:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Morning reception:
    &lt;ul&gt;
      &lt;li&gt;Coffee or Tea&lt;/li&gt;
      &lt;li&gt;Mini biscuits and chocolates&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Lunch:
    &lt;ul&gt;
      &lt;li&gt;Luxury sandwiches &amp;amp; subs with salads, French cheese, grey shrimp, prawns or Parma ham&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;Viking bread&lt;/strong&gt; with smoked salmon&lt;/li&gt;
      &lt;li&gt;Grilled chicken wraps&lt;/li&gt;
      &lt;li&gt;Vegetarian options also available&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Afternoon coffee break:
    &lt;ul&gt;
      &lt;li&gt;Coffee or Soda&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;Candy bars&lt;/strong&gt; or &lt;strong&gt;fruit salad&lt;/strong&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Dinner:
    &lt;ul&gt;
      &lt;li&gt;&lt;strong&gt;BBQ&lt;/strong&gt;&lt;/li&gt;
      &lt;li&gt;Marinated prawn (scampi)&lt;/li&gt;
      &lt;li&gt;&lt;em&gt;Greenway&lt;/em&gt; balls (vegetarian)&lt;/li&gt;
      &lt;li&gt;Spicy &lt;strong&gt;chipolatas&lt;/strong&gt;&lt;/li&gt;
      &lt;li&gt;Marinated chicken satés&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;Steak chimichurri&lt;/strong&gt; cut and grilled &lt;em&gt;à la minute&lt;/em&gt;&lt;/li&gt;
      &lt;li&gt;Coleslaw, tomatoes, cucumbers, carrots, potato salad, mix of salads, red onions and olives&lt;/li&gt;
      &lt;li&gt;Bread, potatoes and sauces&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;subscribing&quot;&gt;Subscribing&lt;/h3&gt;

&lt;p&gt;Anyone who still wants to attend the &lt;strong&gt;free&lt;/strong&gt; 2016 JOIN event at Ordina Mechelen, can subscribe through the link below:&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://www.ordina.be/en/evenementen/2016/join-2016/&quot;&gt;https://www.ordina.be/en/evenementen/2016/join-2016/&lt;/a&gt;&lt;/p&gt;
</description>
        <pubDate>Tue, 27 Sep 2016 00:00:00 +0000</pubDate>
        <link>https://ordina-jworks.github.io/conferences/2016/09/27/JOIN-2016.html</link>
        <guid isPermaLink="true">https://ordina-jworks.github.io/conferences/2016/09/27/JOIN-2016.html</guid>
        
        <category>JOIN</category>
        
        <category>Spring</category>
        
        <category>Docker</category>
        
        <category>Java</category>
        
        <category>Angular</category>
        
        <category>Typescript</category>
        
        
        <category>Conferences</category>
        
      </item>
    
      <item>
        <title>Monitoring with Prometheus</title>
        <description>&lt;p&gt;It is needless to say the world is shifting towards DevOps and microservices.
This holy grail we aim for adds a great deal of complexity.
Monitoring included.
Rather than having to monitor one system,
we are suddenly faced with the challenge to oversee our manifold services.
There are numerous monitoring systems available,
but not all of them are fit for monitoring large, distributed systems.&lt;/p&gt;

&lt;p&gt;Black box monitoring systems like &lt;a href=&quot;https://www.nagios.org&quot;&gt;Nagios&lt;/a&gt; allow you to check if an application is alive and healthy.
This is done by e.g. pinging the service,
checking if there is enough disk space,
or monitoring the CPU usage.
In a world of distributed architectures where high availability and fast response times are key,
it is not sufficient to be only aware if a service is alive.
It is crucial to know how a service is working internally as well.
How many HTTP requests is it receiving?
Are they handled correctly?
How fast are requests handled for different endpoints?
Are there many errors being logged?
How many disk IO operations is the service performing?
These are all important questions that need to be monitored to keep a service functional.&lt;/p&gt;

&lt;p&gt;Prometheus is a &lt;strong&gt;white box monitoring and alerting&lt;/strong&gt; system that is designed for large, scalable environments.
With Prometheus,
we can answer all these questions,
by exposing the internal state of your applications.
By monitoring this internal state,
we can throw alerts and act upon certain events.
For example,
if the average request rate per second of a service goes up,
or the &lt;a href=&quot;https://en.wikipedia.org/wiki/Quantile&quot;&gt;fifty percent quantile&lt;/a&gt; response time of a service suddenly passes a certain threshold,
we could act upon this by upscaling the service.&lt;/p&gt;

&lt;h1 id=&quot;overview&quot;&gt;Overview&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;#rise-of-prometheus&quot;&gt;The Rise of Prometheus&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#architecture&quot;&gt;Architecture&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#data-model&quot;&gt;Data Model&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#slice-dice-with-the-query-language&quot;&gt;Slice &amp;amp; Dice with the Query Language&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#instrumenting-your-services&quot;&gt;Instrumenting Your Services&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#exporters&quot;&gt;Exporters&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#scraping-the-targets&quot;&gt;Scraping the Targets&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#visualization-and-analytics&quot;&gt;Visualization and Analytics&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#alert-alert&quot;&gt;Alert! Alert!&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#monitoring-time&quot;&gt;Monitoring Time!&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#final-words&quot;&gt;Final Words&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;a name=&quot;rise-of-prometheus&quot;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&quot;the-rise-of-prometheus&quot;&gt;The Rise of Prometheus&lt;/h1&gt;

&lt;p&gt;As with most great technologies,
there is usually a great story hiding behind them.
Nothing is different with Prometheus.
Incubated at &lt;a href=&quot;https://soundcloud.com/&quot;&gt;SoundCloud&lt;/a&gt;,
&lt;em&gt;the&lt;/em&gt; social platform for sharing sounds and music,
Prometheus has come a long way.&lt;/p&gt;

&lt;p&gt;When SoundCloud was just a start-up,
they originally developed their application as a single application.
Many features later,
this resulted in one big, monolithic application called &lt;em&gt;the Mothership&lt;/em&gt;.
With only a few thousand artists and users sharing music,
the application performed sufficiently.&lt;/p&gt;

&lt;p&gt;However,
nowadays,
about 12 hours of music is uploaded &lt;em&gt;every minute&lt;/em&gt; to SoundCloud.
The platform is used by hundreds of millions of users every day.
To be able to handle this size of volume,
SoundCloud adapted a more scalable approach.
Deciding against a complete rewrite of their whole technology stack,
they stopped adding new features to the Mothership.
Instead, new features were written as microservices,
living next to the Mothership.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;If you want to know more about how SoundCloud moved from one monolithic application to a microservices architecture,
you can find a &lt;a href=&quot;https://developers.soundcloud.com/blog/building-products-at-soundcloud-part-1-dealing-with-the-monolith&quot;&gt;three-part&lt;/a&gt;
&lt;a href=&quot;https://developers.soundcloud.com/blog/building-products-at-soundcloud-part-2-breaking-the-monolith&quot;&gt;blog post&lt;/a&gt;
&lt;a href=&quot;https://developers.soundcloud.com/blog/building-products-at-soundcloud-part-3-microservices-in-scala-and-finagle&quot;&gt;series&lt;/a&gt;
 on their developer blog (which is an excellent read, by the way).&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Moving towards a microservices architecture paved the way for many possibilities for SoundCloud,
but it also introduced a lot of complexity.
Monitoring a single application is easy.
Monitoring hundreds of different services with thousands of instances is an entirely different story.
SoundCloud’s original monitoring set-up consisted of &lt;a href=&quot;https://graphiteapp.org/&quot;&gt;Graphite&lt;/a&gt; and &lt;a href=&quot;https://github.com/etsy/statsd&quot;&gt;StatsD&lt;/a&gt;.
This setup did not suffice for the new, scalable microservices architecture.
The amount of generated events could not be handled in a reliable way.&lt;/p&gt;

&lt;p&gt;SoundCloud started looking for a new monitoring tool,
while keeping the following requirements in mind:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;A &lt;strong&gt;multi-dimensional data model&lt;/strong&gt;,
where data can be sliced and diced along multiple dimensions like host, service, endpoint and method.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Operational simplicity&lt;/strong&gt;,
so that you can setup monitoring anywhere you want,
whenever you want,
without having to have a Ph.D. in configuration management.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Scalable and decentralized&lt;/strong&gt;,
for independent and reliable monitoring.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;A &lt;strong&gt;powerful query language&lt;/strong&gt; that utilizes the data model for meaningful alerting and visualisation.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Since no existing system combined all of these features,
Prometheus was born from a pet project at SoundCloud.&lt;/p&gt;

&lt;p&gt;Although the project has been &lt;a href=&quot;https://github.com/prometheus&quot;&gt;open source&lt;/a&gt; from the beginning,
SoundCloud did not make any noise about it until the project was mature enough.
In January 2015,
after 2 years of development and internal usage,
the project was &lt;a href=&quot;https://developers.soundcloud.com/blog/prometheus-monitoring-at-soundcloud&quot;&gt;publicly announced&lt;/a&gt;
and a &lt;a href=&quot;https://prometheus.io&quot;&gt;website&lt;/a&gt; was put online.
The amount of attention it received was totally unexpected for the team at SoundCloud.
After a &lt;a href=&quot;https://news.ycombinator.com/item?id=8995696&quot;&gt;post on Hacker News&lt;/a&gt;,
which made it all the way to the top,
things got serious.
There was a sharp rise in contributions, questions, GitHub issues, conference invites, and all that stuff.&lt;/p&gt;

&lt;p&gt;The following image depicts the amount of stars the project received on GitHub since its inception.&lt;/p&gt;

&lt;p style=&quot;text-align: center;&quot;&gt;
  &lt;img style=&quot;max-width: 640px;&quot; alt=&quot;Prometheus Github Stars&quot; src=&quot;/img/prometheus/prometheus-github-stars.png&quot; /&gt;
&lt;/p&gt;

&lt;p&gt;&lt;a name=&quot;architecture&quot;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&quot;architecture&quot;&gt;Architecture&lt;/h1&gt;

&lt;p&gt;Prometheus’ architecture is pretty straightforward.&lt;/p&gt;

&lt;p&gt;Prometheus servers scrape (pull) metrics from &lt;em&gt;instrumented jobs&lt;/em&gt;.
If a service is unable to be instrumented,
the server can scrape metrics from an intermediary &lt;em&gt;push gateway&lt;/em&gt;.
There is no distributed storage.
Prometheus servers store all metrics locally.
They can run rules over this data and generate new time series,
or trigger alerts. Servers also provide an API to query the data.
Grafana utilizes this functionality and can be used to build dashboards.&lt;/p&gt;

&lt;p&gt;Finally,
Prometheus servers know which targets to scrape from due to service discovery,
or static configuration.
Service discovery is more common and also recommended,
as it allows you to dynamically discover targets.&lt;/p&gt;

&lt;p style=&quot;text-align: center;&quot;&gt;
  &lt;img alt=&quot;Prometheus Architecture&quot; src=&quot;/img/prometheus/prometheus-architecture.svg&quot; /&gt;
&lt;/p&gt;

&lt;p&gt;&lt;a name=&quot;architecture&quot;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&quot;data-model&quot;&gt;Data Model&lt;/h1&gt;

&lt;p&gt;At its core,
Prometheus stores all data as &lt;strong&gt;time series&lt;/strong&gt;.
A time series is a stream of timestamped values that belong to the same metric and the same labels.
The labels cause the metrics to be multi-dimensional.&lt;/p&gt;

&lt;p&gt;For example,
if we wish to monitor the total amount of HTTP requests on our API,
we could create a metric named &lt;strong&gt;api_http_requests_total&lt;/strong&gt;.
Now,
to make this metric multi-dimensional,
we can add labels.
Labels are simple key value pairs.
For HTTP requests,
we can attach a label named &lt;strong&gt;method&lt;/strong&gt; that takes the HTTP method as value.
Other possible labels include the endpoint that is called on our API,
and the HTTP status returned by the server for that request.&lt;/p&gt;

&lt;p&gt;The notation for a metric like that could be the following:&lt;/p&gt;

&lt;div class=&quot;language-javascript highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nx&quot;&gt;api_http_requests_total&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;method&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;GET&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;endpoint&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;/api/posts&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;status&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;200&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Now,
if we start sampling values for this metric,
we could end up with the following time series:&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Metrics&lt;/th&gt;
      &lt;th&gt;Timestamp&lt;/th&gt;
      &lt;th&gt;Value&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;api_http_requests_total{method=&quot;GET&quot;, endpoint=&quot;/api/posts&quot;, status=&quot;200&quot;}&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;@1464623917237&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;68856&lt;/code&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;api_http_requests_total{method=&quot;GET&quot;, endpoint=&quot;/api/posts&quot;, status=&quot;500&quot;}&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;@1464623917237&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;5567&lt;/code&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;api_http_requests_total{method=&quot;GET&quot;, endpoint=&quot;/api/posts&quot;, status=&quot;200&quot;}&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;@1464624516508&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;76909&lt;/code&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;api_http_requests_total{method=&quot;GET&quot;, endpoint=&quot;/api/posts&quot;, status=&quot;500&quot;}&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;@1464624516508&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;6789&lt;/code&gt;&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;One of the great aspects of time series
is the fact that the amount of generated time series is independent of the amount of events.
Even though your server might suddenly get a spike in traffic,
the amount of time series generated stays the same.
Only the outputted value of the time series is different.
This is wonderful for scalability.&lt;/p&gt;

&lt;p&gt;Prometheus offers four metric types which can be used to generate one or multiple time series.&lt;/p&gt;

&lt;p&gt;A &lt;strong&gt;counter&lt;/strong&gt; is a metric which is a numerical value that is only incremented,
never decremented.
Examples include the total amount of requests served,
how many exceptions that occur, etc.&lt;/p&gt;

&lt;p&gt;A &lt;strong&gt;gauge&lt;/strong&gt; is a metric similar to the counter. It is a numerical value that can go either up or down.
Think of memory usage, cpu usage, amount of threads, or perhaps a temperature.&lt;/p&gt;

&lt;p&gt;A &lt;strong&gt;&lt;a href=&quot;https://www.google.com/search?q=histogram&quot;&gt;histogram&lt;/a&gt;&lt;/strong&gt; is a metric that samples observations.
These observations are counted and placed into configurable buckets.
Upon being scraped,
a &lt;em&gt;histogram&lt;/em&gt; provides multiple time series,
including one for each bucket,
one for the sum of all values,
and one for the count of the events that have been observed.
A typical use case for a histogram is the measuring of response times.&lt;/p&gt;

&lt;p&gt;A &lt;strong&gt;summary&lt;/strong&gt; is similar to a &lt;em&gt;histogram&lt;/em&gt;,
but it also calculates configurable &lt;a href=&quot;https://en.wikipedia.org/wiki/Quantile&quot;&gt;quantiles&lt;/a&gt;.
Depending on your requirements,
you either use a &lt;a href=&quot;https://prometheus.io/docs/practices/histograms/&quot;&gt;histogram or a summary&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;a name=&quot;slice-dice-with-the-query-language&quot;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&quot;slice--dice-with-the-query-language&quot;&gt;Slice &amp;amp; Dice with the Query Language&lt;/h1&gt;

&lt;p&gt;A powerful data model needs a powerful query language.
Prometheus offers one,
and it is also one of Prometheus’ key features.
The Prometheus query language,
or &lt;em&gt;promql&lt;/em&gt;,
is an expressive, functional language.
One which apparently,
by the way,
is &lt;a href=&quot;http://www.robustperception.io/conways-life-in-prometheus/&quot;&gt;Turing complete&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;The language is easy to use.
Monitoring things like CPU usage,
memory usage, amount of HTTP request served, etc. are pretty straightforward,
and the language makes it effortless.
Using an &lt;strong&gt;instant vector selector&lt;/strong&gt;,
you can select time series from a metric.&lt;/p&gt;

&lt;p&gt;For example,
Continuing with our API example,
we can select all the time series of the metric &lt;code class=&quot;highlighter-rouge&quot;&gt;api_http_requests_total&lt;/code&gt;:&lt;/p&gt;

&lt;div class=&quot;language-javascript highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nx&quot;&gt;api_http_requests_total&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;We can dive a little bit deeper by filtering these time series on their labels using curly braces (&lt;code class=&quot;highlighter-rouge&quot;&gt;&lt;span class=&quot;p&quot;&gt;{}&lt;/span&gt;&lt;/code&gt;).
Let’s say we want to monitor requests that failed due to an internal server error.
We can achieve this by selecting the time series of the metric &lt;code class=&quot;highlighter-rouge&quot;&gt;api_http_requests_total&lt;/code&gt;
where the label &lt;code class=&quot;highlighter-rouge&quot;&gt;status&lt;/code&gt; is set to &lt;code class=&quot;highlighter-rouge&quot;&gt;500&lt;/code&gt;.&lt;/p&gt;

&lt;div class=&quot;language-javascript highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nx&quot;&gt;api_http_requests_total&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;status&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;500&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;We can also define a time window if we only want to have time series of a certain period.
This is done by using a &lt;strong&gt;range vector selector&lt;/strong&gt;.
The following example selects time series of the last hour:&lt;/p&gt;

&lt;div class=&quot;language-javascript highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nx&quot;&gt;api_http_requests_total&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;h&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;The time duration is specified as a number followed by a character depicting the time unit:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;s&lt;/strong&gt; - seconds&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;m&lt;/strong&gt; - minutes&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;h&lt;/strong&gt; - hours&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;d&lt;/strong&gt; - days&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;w&lt;/strong&gt; - weeks&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;y&lt;/strong&gt; - years&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;You can go further back in time by using an &lt;code class=&quot;highlighter-rouge&quot;&gt;offset&lt;/code&gt;.
This example selects time series that happened at least an hour ago:&lt;/p&gt;

&lt;div class=&quot;language-javascript highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nx&quot;&gt;api_http_requests_total&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;offset&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;h&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;We can use functions in our queries to create more useful results.
The &lt;code class=&quot;highlighter-rouge&quot;&gt;rate()&lt;/code&gt; function calculates the per-second average rate of time series in a range vector.
Combining all the above tools,
we can get the rates of HTTP requests of a specific timeframe.
The query below will calculate the per-second rates of all HTTP requests
that occurred in the last 5 minutes an hour ago:&lt;/p&gt;

&lt;div class=&quot;language-javascript highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nx&quot;&gt;rate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;api_http_requests_total&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;status&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;500&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;offset&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;h&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;A slightly more complex example selects the top 3 endpoints which have the most HTTP requests
not being served correctly in the last hour:&lt;/p&gt;

&lt;div class=&quot;language-javascript highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nx&quot;&gt;topk&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
  &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;nx&quot;&gt;rate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;api_http_requests_total&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;status&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;500&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;h&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;by&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;endpoint&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;As you can see,
Prometheus can provide a lot of useful information with several simple queries that only have a few basic functions and operators.
There is also support for sorting, aggregation, interpolation and other mathematical wizardry that you can find in other query languages.&lt;/p&gt;

&lt;p&gt;&lt;a name=&quot;instrumenting-your-services&quot;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&quot;instrumenting-your-services&quot;&gt;Instrumenting Your Services&lt;/h1&gt;

&lt;p&gt;One of the requirements to be able to query data and get results,
obviously,
is the fact that there must be data that can be queried.
Generating data can be done by instrumenting your services.
Prometheus offers client libraries for
&lt;a href=&quot;https://github.com/prometheus/client_golang&quot;&gt;Go&lt;/a&gt;,
&lt;a href=&quot;https://github.com/prometheus/client_java&quot;&gt;Java/Scala&lt;/a&gt;,
&lt;a href=&quot;https://github.com/prometheus/client_python&quot;&gt;Python&lt;/a&gt; and
&lt;a href=&quot;https://github.com/prometheus/client_ruby&quot;&gt;Ruby&lt;/a&gt;.
There is also a lengthy list of unofficial third-party clients for other languages,
including clients for Bash and Node.js.
These clients enable you to expose metrics endpoints through HTTP.&lt;/p&gt;

&lt;p&gt;This is totally different compared to other,
more traditional,
monitoring tools.
Normally,
the application is unaware that it is being monitored.
With Prometheus,
you must instrument your code
and explicitly define the metrics you want to expose.
This allows you to generate highly granular data which you can query.
However,
this technique is not much different than logging.
Logging statements are,
most of the time,
also explicitly defined in the code,
so why not for monitoring as well?&lt;/p&gt;

&lt;p&gt;For short-lived jobs,
like cronjobs,
scraping may be too slow to gather the metrics.
For these use cases,
Prometheus offers an alternative,
called the &lt;a href=&quot;https://github.com/prometheus/pushgateway&quot;&gt;Pushgateway&lt;/a&gt;.
Before a job disappears,
it can push metrics to this gateway,
and Prometheus can scrape the metrics from this gateway later on.&lt;/p&gt;

&lt;p&gt;&lt;a name=&quot;exporters&quot;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&quot;exporters&quot;&gt;Exporters&lt;/h1&gt;

&lt;p&gt;Not everything can be instrumented.
Third-party tools that do not support Prometheus metrics natively,
can be monitored with &lt;strong&gt;exporters&lt;/strong&gt;.
Exporters can collect statistics and existing metrics,
and convert them to Prometheus metrics.
An exporter,
just like an instrumented service,
exposes these metrics through an endpoint,
and can be scraped by Prometheus.&lt;/p&gt;

&lt;p&gt;A &lt;a href=&quot;https://prometheus.io/docs/instrumenting/exporters/&quot;&gt;large variety of exporters&lt;/a&gt; is already available.
If you want to monitor third-party software that does not have an exporter publicly available,
you can write your own &lt;a href=&quot;https://prometheus.io/docs/instrumenting/writing_exporters/&quot;&gt;custom exporter&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a name=&quot;scraping-the-targets&quot;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&quot;scraping-the-targets&quot;&gt;Scraping the Targets&lt;/h1&gt;

&lt;p&gt;Pulling metrics from instances is called scraping.
Scraping is done at configurable intervals by the Prometheus server.
Prometheus allows you to configure &lt;strong&gt;jobs&lt;/strong&gt; that fetch time series from &lt;strong&gt;instances&lt;/strong&gt;.&lt;/p&gt;

&lt;div class=&quot;language-yml highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;s&quot;&gt;global&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;s&quot;&gt;scrape_interval&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;15s&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# Scrape targets every 15 seconds&lt;/span&gt;
  &lt;span class=&quot;s&quot;&gt;scrape_timeout&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;15s&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# Timeout after 15 seconds&lt;/span&gt;

  &lt;span class=&quot;c1&quot;&gt;# Attach the label monitor=dev-monitor to all scraped time series scraped by this server&lt;/span&gt;
  &lt;span class=&quot;s&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;monitor&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;dev-monitor'&lt;/span&gt;

&lt;span class=&quot;s&quot;&gt;scrape_configs&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;job_name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;job-name&quot;&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;scrape_interval&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;10s&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# Override the default global interval for this job&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;scrape_timeout&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;10s&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# Override the default global timeout for this job&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;target_groups&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# First group of scrape targets&lt;/span&gt;
    &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;targets&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;pi&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;localhost:9100'&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;localhost:9101'&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;]&lt;/span&gt;
      &lt;span class=&quot;s&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;s&quot;&gt;group&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;first-group'&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# Second group of scrape targets&lt;/span&gt;
    &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;targets&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;pi&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;localhost:9200'&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;localhost:9201'&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;]&lt;/span&gt;
      &lt;span class=&quot;s&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;s&quot;&gt;group&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;second-group'&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;This configuration file is pretty self-explanatory.
You can define defaults for all jobs in the &lt;code class=&quot;highlighter-rouge&quot;&gt;global&lt;/code&gt; root element.
These defaults can then be overridden by each job,
if necessary.&lt;/p&gt;

&lt;p&gt;A job itself has a name and a list of target groups.
In most cases,
a job has one list of targets (one target group),
but Prometheus allows you to split these between different groups,
so you can add different labels to each scraped metric of that group.
Next to your own custom labels,
Prometheus will additionally append the &lt;code class=&quot;highlighter-rouge&quot;&gt;job&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;instance&lt;/code&gt; labels to the sampled metrics automatically.&lt;/p&gt;

&lt;p&gt;&lt;a name=&quot;visualization-and-analytics&quot;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&quot;visualization-and-analytics&quot;&gt;Visualization and Analytics&lt;/h1&gt;

&lt;p&gt;Prometheus has its own dashboard,
called &lt;strong&gt;&lt;a href=&quot;https://github.com/prometheus/promdash&quot;&gt;PromDash&lt;/a&gt;&lt;/strong&gt;,
but it has been &lt;strong&gt;deprecated&lt;/strong&gt; in favor of &lt;a href=&quot;http://grafana.org&quot;&gt;Grafana&lt;/a&gt;.
Grafana supports Prometheus metrics out-of-the-box
and makes setting up metrics visualization effortless.
After adding a Prometheus data source,
you can immediately start creating dashboards using &lt;a href=&quot;#slice-dice-with-the-query-language&quot;&gt;PromQL&lt;/a&gt;:&lt;/p&gt;

&lt;div class=&quot;figures&quot;&gt;
  &lt;a href=&quot;/img/prometheus/grafana-datasource.jpg&quot;&gt;
  &lt;figure&gt;
      &lt;img style=&quot;max-width: 320px;&quot; alt=&quot;Prometheus Datasource&quot; src=&quot;/img/prometheus/grafana-datasource.jpg&quot; /&gt;
      &lt;figcaption&gt;Step 1: Create datasource&lt;/figcaption&gt;
  &lt;/figure&gt;
  &lt;/a&gt;

  &lt;a href=&quot;/img/prometheus/grafana-dashboard.jpg&quot;&gt;
  &lt;figure&gt;
    &lt;img style=&quot;max-width: 320px;&quot; alt=&quot;Grafana Dashboard&quot; src=&quot;/img/prometheus/grafana-dashboard.jpg&quot; /&gt;
    &lt;figcaption&gt;Step 2: Profit&lt;/figcaption&gt;
  &lt;/figure&gt;
  &lt;/a&gt;
&lt;/div&gt;

&lt;p&gt;&lt;a name=&quot;alert-alert&quot;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&quot;alert-alert&quot;&gt;Alert! Alert!&lt;/h1&gt;

&lt;p&gt;Prometheus provides an &lt;a href=&quot;https://github.com/prometheus/alertmanager&quot;&gt;Alert Manager&lt;/a&gt;.
This Alert Manager is highly configurable and supports many notification methods natively.
You can define &lt;strong&gt;routes&lt;/strong&gt; and &lt;strong&gt;receivers&lt;/strong&gt;,
so you have fine-grained control over every alert and how it is treated.
It is possible to suppress alerts and define inhibition rules,
so you can prevent getting thousands of the same alert if a many-node cluster goes down.&lt;/p&gt;

&lt;p&gt;Alerts can be generated by defining &lt;strong&gt;alerting rules&lt;/strong&gt;.
This is done in Prometheus and not in the Alert Manager.
Here are a few simple alerting rule examples:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;# Alert for any instance that have a median request latency &amp;gt;1s.
ALERT APIHighRequestLatency
IF api_http_request_latencies_second{quantile=&quot;0.5&quot;} &amp;gt; 1
FOR 1m
LABELS { severity=&quot;critical&quot;}
ANNOTATIONS {
  summary = &quot;High request latency on &quot;,
  description = &quot; has a median request latency above 1s (current value: s)&quot;,
}

ALERT CpuUsage
IF cpu_usage_total &amp;gt; 95
FOR 1m
LABELS { severity=&quot;critical&quot;}
ANNOTATIONS {
  summary = &quot;YOU MUST CONSTRUCT ADDITIONAL PYLONS&quot;
  description = &quot;CPU usage is above 95%&quot;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;After an alert is generated and sent to the Alert Manager,
it can be routed using &lt;strong&gt;routes&lt;/strong&gt;.
There is one root route on which each incoming alert enters,
and you can define child routes to route alerts to the correct receiver.
These routes can be configured using a YAML configuration file:&lt;/p&gt;

&lt;div class=&quot;language-yml highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# The root route on which each incoming alert enters.&lt;/span&gt;
&lt;span class=&quot;s&quot;&gt;route&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;c1&quot;&gt;# The default receiver&lt;/span&gt;
  &lt;span class=&quot;s&quot;&gt;receiver&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;team-X'&lt;/span&gt;
  &lt;span class=&quot;c1&quot;&gt;# The child route trees.&lt;/span&gt;
  &lt;span class=&quot;s&quot;&gt;routes&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;c1&quot;&gt;# This is a regular expressiong based route&lt;/span&gt;
  &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;match_re&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;s&quot;&gt;service&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;^(foo|bar)$&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;receiver&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;team-foobar&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# Another child route&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;routes&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;match&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;s&quot;&gt;severity&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;critical&lt;/span&gt;
      &lt;span class=&quot;s&quot;&gt;receiver&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;team-critical&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;There are multiple types of &lt;a href=&quot;https://prometheus.io/docs/alerting/configuration/#receiver-receiver&quot;&gt;&lt;strong&gt;receivers&lt;/strong&gt;&lt;/a&gt; to which you can push notifications to.
You can push alert notifications to SMTP,
&lt;a href=&quot;https://www.hipchat.com&quot;&gt;HipChat&lt;/a&gt;,
&lt;a href=&quot;https://www.pagerduty.com&quot;&gt;PagerDuty&lt;/a&gt;,
&lt;a href=&quot;https://pushover.net/&quot;&gt;PushOver&lt;/a&gt;,
&lt;a href=&quot;https://slack.com&quot;&gt;Slack&lt;/a&gt; and &lt;a href=&quot;https://www.opsgenie.com/&quot;&gt;OpsGenie&lt;/a&gt;.
Additionally,
you can use a web hook to send HTTP POST requests to a certain endpoint with the alert as JSON,
if you wish to push notifications to somewhere else.
Check out &lt;a href=&quot;http://www.robustperception.io/audio-alerting-with-prometheus/&quot;&gt;this guy’s audio alarm&lt;/a&gt;,
which alerts him when his internet goes down!&lt;/p&gt;

&lt;p&gt;The receivers are configured in the same YAML configuration file:&lt;/p&gt;

&lt;div class=&quot;language-yml highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;s&quot;&gt;receivers&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# Email receiver&lt;/span&gt;
&lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;team-X'&lt;/span&gt;
  &lt;span class=&quot;s&quot;&gt;email_configs&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;to&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;alerts@team-x.com'&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Slack receiver that sends alerts to the #general channel.&lt;/span&gt;
&lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;team-foobar'&lt;/span&gt;
  &lt;span class=&quot;s&quot;&gt;slack_configs&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;api_url&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;https://foobar.slack.com/services/hooks/incoming-webhook?token=&amp;lt;token&amp;gt;'&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;channel&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;general'&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Webhook receiver with a custom endpoint&lt;/span&gt;
&lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;team-critical'&lt;/span&gt;
  &lt;span class=&quot;s&quot;&gt;webhook_configs&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;url&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;team.critical.com'&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;&lt;a name=&quot;monitoring-time&quot;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&quot;monitoring-time&quot;&gt;Monitoring Time!&lt;/h1&gt;

&lt;p&gt;Do you wish to get your hands dirty quickly with Prometheus?
Perfect!
I have prepared a project for demonstration purposes,
which can be found &lt;a href=&quot;https://github.com/ordina-jworks/prometheus-demo&quot;&gt;on the Ordina JWorks GitHub repository&lt;/a&gt;.
The project can be set up using only one command,
leveraging &lt;a href=&quot;https://docker.com/getdocker&quot;&gt;Docker&lt;/a&gt; and &lt;a href=&quot;https://www.gnu.org/s/make/manual/make.html&quot;&gt;Make&lt;/a&gt;.
It covers most of the features discussed in this blog post.&lt;/p&gt;

&lt;p&gt;First clone the project with Git:&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;gp&quot;&gt;$ &lt;/span&gt;git clone git@github.com:ordina-jworks/prometheus-demo.git
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;After the project is cloned,
run &lt;code class=&quot;highlighter-rouge&quot;&gt;make&lt;/code&gt; in the project directory:&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;gp&quot;&gt;$ &lt;/span&gt;make
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;This will compile all applications,
build or pull all necessary Docker images,
and start the complete project using Docker Compose.
The following containers are started:&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;gp&quot;&gt;$ &lt;/span&gt;docker ps
CONTAINER ID        IMAGE                              COMMAND                  PORTS                     NAMES
c620b49edf4c        prom/alertmanager                  &lt;span class=&quot;s2&quot;&gt;&quot;/bin/alertmanager -c&quot;&lt;/span&gt;   0.0.0.0:32902-&amp;gt;9093/tcp   prometheusdemo_alertmanager_1
67b461b6a44b        grafana/grafana                    &lt;span class=&quot;s2&quot;&gt;&quot;/run.sh&quot;&lt;/span&gt;                0.0.0.0:32903-&amp;gt;3000/tcp   prometheusdemo_grafana_1
920792d123bd        google/cadvisor                    &lt;span class=&quot;s2&quot;&gt;&quot;/usr/bin/cadvisor -l&quot;&lt;/span&gt;   0.0.0.0:32900-&amp;gt;8080/tcp   prometheusdemo_cadvisor_1
215c20eb849b        ordina-jworks/prometheus-prommer   &lt;span class=&quot;s2&quot;&gt;&quot;/bin/sh -c /entrypoi&quot;&lt;/span&gt;   0.0.0.0:32901-&amp;gt;9090/tcp   prometheusdemo_prometheus_1
f3cfc2f63f00        tomverelst/prommer                 &lt;span class=&quot;s2&quot;&gt;&quot;/bin/prommer -target&quot;&lt;/span&gt;                             prometheusdemo_prommer_1
574f14998424        ordina-jworks/voting-app           &lt;span class=&quot;s2&quot;&gt;&quot;/main&quot;&lt;/span&gt;                  0.0.0.0:32899-&amp;gt;8080/tcp   prometheusdemo_voting-app_1
66f2a00fcbcb        ordina-jworks/alert-console        &lt;span class=&quot;s2&quot;&gt;&quot;/main&quot;&lt;/span&gt;                  0.0.0.0:32898-&amp;gt;8080/tcp   prometheusdemo_alert-console_1
4fd707d4e80c        ordina-jworks/voting-generator     &lt;span class=&quot;s2&quot;&gt;&quot;/main -vote=cat -max&quot;&lt;/span&gt;   8080/tcp                  prometheusdemo_vote-cats_1
5b876a131ad0        ordina-jworks/voting-generator     &lt;span class=&quot;s2&quot;&gt;&quot;/main -vote=dog -max&quot;&lt;/span&gt;   8080/tcp                  prometheusdemo_vote-dogs_1
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;As you can see,
a lot of containers are started!
You can view the public ports of the containers in this list,
which you need to access the applications.
The project consists of the following components:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/prometheus/prometheus&quot;&gt;&lt;strong&gt;Prometheus&lt;/strong&gt;&lt;/a&gt; which scrapes the metrics and throws alerts&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/grafana/grafana&quot;&gt;&lt;strong&gt;Grafana&lt;/strong&gt;&lt;/a&gt; to visualize metrics and show fancy graphs&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/prometheus/alertmanager&quot;&gt;&lt;strong&gt;Alert Manager&lt;/strong&gt;&lt;/a&gt; to collect all alerts and route them with a rule based system&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/google/cadvisor&quot;&gt;&lt;strong&gt;cAdvisor&lt;/strong&gt;&lt;/a&gt; which exposes container and host metrics&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/tomverelst/prommer&quot;&gt;&lt;strong&gt;Prommer&lt;/strong&gt;&lt;/a&gt;, a custom Prometheus target discovery tool&lt;/li&gt;
  &lt;li&gt;An &lt;strong&gt;alert console&lt;/strong&gt; which displays the alerts in the console&lt;/li&gt;
  &lt;li&gt;A &lt;strong&gt;voting application&lt;/strong&gt; which registers and counts votes&lt;/li&gt;
  &lt;li&gt;A &lt;strong&gt;voting generator&lt;/strong&gt; which generates votes&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The voting application exposes a custom metric called &lt;code class=&quot;highlighter-rouge&quot;&gt;voting_amount_total&lt;/code&gt;.
This metric holds the total amount of votes and is labeled by the type of vote,
e.g. &lt;code class=&quot;highlighter-rouge&quot;&gt;voting_amount_total{name=dog}&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;An alerting rule is configured in Prometheus that checks for the amount of votes.
Once it passes a certain threshold,
the alert is fired.
This alert is sent to the &lt;strong&gt;Alert Manager&lt;/strong&gt;,
which in turn routes it to the custom &lt;strong&gt;alert console&lt;/strong&gt; through a webhook.&lt;/p&gt;

&lt;div class=&quot;figures&quot;&gt;
  &lt;a href=&quot;/img/prometheus/demo-rule-inactive.png&quot;&gt;
  &lt;figure&gt;
      &lt;img style=&quot;max-width: 320px;&quot; alt=&quot;Inactive alert&quot; src=&quot;/img/prometheus/demo-rule-inactive.png&quot; /&gt;
      &lt;figcaption&gt;Inactive alert&lt;/figcaption&gt;
  &lt;/figure&gt;
  &lt;/a&gt;


&lt;/div&gt;

&lt;div class=&quot;figures&quot;&gt;
  &lt;a href=&quot;/img/prometheus/demo-rule-active.png&quot;&gt;
  &lt;figure&gt;
    &lt;img style=&quot;max-width: 320px;&quot; alt=&quot;Active alert&quot; src=&quot;/img/prometheus/demo-rule-active.png&quot; /&gt;
    &lt;figcaption&gt;The alert is fired&lt;/figcaption&gt;
  &lt;/figure&gt;
  &lt;/a&gt;
&lt;/div&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;The &lt;strong&gt;alert console&lt;/strong&gt; logs the JSON body of the POST request from the &lt;strong&gt;Alert Manager&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;We can check the output of these logs using Docker Compose:&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;gp&quot;&gt;$ &lt;/span&gt;docker-compose logs -f --tail&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;all&quot;&lt;/span&gt; alert-console
Attaching to prometheusdemo_alert-console_1
alert-console_1  | &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;receiver&quot;&lt;/span&gt;:&lt;span class=&quot;s2&quot;&gt;&quot;alert_console&quot;&lt;/span&gt;,&lt;span class=&quot;s2&quot;&gt;&quot;status&quot;&lt;/span&gt;:&lt;span class=&quot;s2&quot;&gt;&quot;firing&quot;&lt;/span&gt;,&lt;span class=&quot;s2&quot;&gt;&quot;alerts&quot;&lt;/span&gt;:[&lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;status&quot;&lt;/span&gt;:&lt;span class=&quot;s2&quot;&gt;&quot;firing&quot;&lt;/span&gt;,&lt;span class=&quot;s2&quot;&gt;&quot;labels&quot;&lt;/span&gt;:&lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;alertname&quot;&lt;/span&gt;:&lt;span class=&quot;s2&quot;&gt;&quot;TooManyCatVotes&quot;&lt;/span&gt;,
&lt;span class=&quot;s2&quot;&gt;&quot;instance&quot;&lt;/span&gt;:&lt;span class=&quot;s2&quot;&gt;&quot;172.19.0.5:8080&quot;&lt;/span&gt;,&lt;span class=&quot;s2&quot;&gt;&quot;job&quot;&lt;/span&gt;:&lt;span class=&quot;s2&quot;&gt;&quot;voting-app&quot;&lt;/span&gt;,&lt;span class=&quot;s2&quot;&gt;&quot;name&quot;&lt;/span&gt;:&lt;span class=&quot;s2&quot;&gt;&quot;cat&quot;&lt;/span&gt;,&lt;span class=&quot;s2&quot;&gt;&quot;severity&quot;&lt;/span&gt;:&lt;span class=&quot;s2&quot;&gt;&quot;critical&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;,&lt;span class=&quot;s2&quot;&gt;&quot;annotations&quot;&lt;/span&gt;:&lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;summary&quot;&lt;/span&gt;:&lt;span class=&quot;s2&quot;&gt;&quot;Too many votes for cats!
&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;,&lt;span class=&quot;s2&quot;&gt;&quot;startsAt&quot;&lt;/span&gt;:&lt;span class=&quot;s2&quot;&gt;&quot;2016-09-22T17:09:22.807Z&quot;&lt;/span&gt;,&lt;span class=&quot;s2&quot;&gt;&quot;endsAt&quot;&lt;/span&gt;:&lt;span class=&quot;s2&quot;&gt;&quot;0001-01-01T00:00:00Z&quot;&lt;/span&gt;,&lt;span class=&quot;s2&quot;&gt;&quot;generatorURL&quot;&lt;/span&gt;:&lt;span class=&quot;s2&quot;&gt;&quot;http://215c20eb849b:9090/graph#%5B%7B%22expr%
22%3A%22votes_amount_total%7Bname%3D%5C%22cat%5C%22%7D%20%3E%20100%22%2C%22tab%22%3A0%7D%5D&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;}]&lt;/span&gt;,&lt;span class=&quot;s2&quot;&gt;&quot;groupLabels&quot;&lt;/span&gt;:&lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;alertname&quot;&lt;/span&gt;:&lt;span class=&quot;s2&quot;&gt;&quot;TooManyCatV
otes&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;,&lt;span class=&quot;s2&quot;&gt;&quot;commonLabels&quot;&lt;/span&gt;:&lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;alertname&quot;&lt;/span&gt;:&lt;span class=&quot;s2&quot;&gt;&quot;TooManyCatVotes&quot;&lt;/span&gt;,&lt;span class=&quot;s2&quot;&gt;&quot;instance&quot;&lt;/span&gt;:&lt;span class=&quot;s2&quot;&gt;&quot;172.19.0.5:8080&quot;&lt;/span&gt;,&lt;span class=&quot;s2&quot;&gt;&quot;job&quot;&lt;/span&gt;:&lt;span class=&quot;s2&quot;&gt;&quot;voting-app&quot;&lt;/span&gt;,&lt;span class=&quot;s2&quot;&gt;&quot;name&quot;&lt;/span&gt;:&lt;span class=&quot;s2&quot;&gt;&quot;cat&quot;&lt;/span&gt;,&lt;span class=&quot;s2&quot;&gt;&quot;severity&quot;&lt;/span&gt;:&lt;span class=&quot;s2&quot;&gt;&quot;critical
&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;,&lt;span class=&quot;s2&quot;&gt;&quot;commonAnnotations&quot;&lt;/span&gt;:&lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;summary&quot;&lt;/span&gt;:&lt;span class=&quot;s2&quot;&gt;&quot;Too many votes for cats!&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;,&lt;span class=&quot;s2&quot;&gt;&quot;externalURL&quot;&lt;/span&gt;:&lt;span class=&quot;s2&quot;&gt;&quot;http://c620b49edf4c:9093&quot;&lt;/span&gt;,&lt;span class=&quot;s2&quot;&gt;&quot;version&quot;&lt;/span&gt;:&lt;span class=&quot;s2&quot;&gt;&quot;3&quot;&lt;/span&gt;,&lt;span class=&quot;s2&quot;&gt;&quot;groupKey&quot;&lt;/span&gt;:101200
6562800295578&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;grafana&quot;&gt;Grafana&lt;/h3&gt;

&lt;p&gt;The default credentials for Grafana are &lt;code class=&quot;highlighter-rouge&quot;&gt;admin:admin&lt;/code&gt;.
After logging in,
you must first configure a &lt;strong&gt;Prometheus data source&lt;/strong&gt;.
Prometheus is available at &lt;code class=&quot;highlighter-rouge&quot;&gt;http://prometheus:9090&lt;/code&gt; (from within the container).&lt;/p&gt;

&lt;div class=&quot;figures&quot;&gt;
  &lt;a href=&quot;/img/prometheus/grafana-datasource.jpg&quot;&gt;
  &lt;figure&gt;
      &lt;img style=&quot;max-width: 320px;&quot; alt=&quot;Configuring Data source&quot; src=&quot;/img/prometheus/grafana-datasource.jpg&quot; /&gt;
      &lt;figcaption&gt;Configuring the data source&lt;/figcaption&gt;
  &lt;/figure&gt;
  &lt;/a&gt;

  &lt;a href=&quot;/img/prometheus/grafana-dashboard.jpg&quot;&gt;
  &lt;figure&gt;
    &lt;img style=&quot;max-width: 320px;&quot; alt=&quot;Grafana Dashboard&quot; src=&quot;/img/prometheus/grafana-dashboard.jpg&quot; /&gt;
    &lt;figcaption&gt;Visualizing metrics&lt;/figcaption&gt;
  &lt;/figure&gt;
  &lt;/a&gt;
&lt;/div&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h3 id=&quot;cadvisor&quot;&gt;cAdvisor&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;cAdvisor&lt;/strong&gt; also has a simple dashboard which displays most important host and container metrics.
Since Prometheus scrapes cAdvisor,
these metrics are also available from Grafana.&lt;/p&gt;

&lt;div class=&quot;figures&quot;&gt;
  &lt;a href=&quot;/img/prometheus/cadvisor-throughput.png&quot;&gt;
  &lt;figure&gt;
      &lt;img style=&quot;max-width: 320px;&quot; alt=&quot;Throughput&quot; src=&quot;/img/prometheus/cadvisor-throughput.png&quot; /&gt;
      &lt;figcaption&gt;Network Throughput&lt;/figcaption&gt;
  &lt;/figure&gt;

  &lt;/a&gt;

  &lt;a href=&quot;/img/prometheus/cadvisor-cpu-usage.png&quot;&gt;
  &lt;figure&gt;
      &lt;img style=&quot;max-width: 320px;&quot; alt=&quot;CPU Usage per Core&quot; src=&quot;/img/prometheus/cadvisor-cpu-usage.png&quot; /&gt;
      &lt;figcaption&gt;CPU Usage per Core&lt;/figcaption&gt;
  &lt;/figure&gt;
  &lt;/a&gt;
&lt;/div&gt;

&lt;p&gt;&lt;a name=&quot;final-words&quot;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&quot;final-words&quot;&gt;Final Words&lt;/h1&gt;

&lt;p&gt;Just a few months ago,
the Prometheus team &lt;a href=&quot;https://prometheus.io/blog/2016/05/09/prometheus-to-join-the-cloud-native-computing-foundation/&quot;&gt;joined the Cloud Native Computing Foundation&lt;/a&gt;.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Today, we are excited to announce that the CNCF’s Technical Oversight Committee voted unanimously to accept Prometheus as a second hosted project after Kubernetes!
You can find more information about these plans in the &lt;a href=&quot;https://cncf.io/news/announcement/2016/05/cloud-native-computing-foundation-accepts-prometheus-second-hosted-project&quot;&gt;official press release&lt;/a&gt; by the CNCF.&lt;/p&gt;

  &lt;p&gt;By joining the CNCF, we hope to establish a clear and sustainable project governance model, as well as benefit from the resources, infrastructure, and advice that the independent foundation provides to its members.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;em&gt;Cloud Native Computing Foundation&lt;/em&gt; (&lt;a href=&quot;http://cncf.io/&quot;&gt;CNCF&lt;/a&gt;) is a nonprofit, open standardization organisation which commits itself to advance the development of cloud native technologies,
formed under the Linux Foundation.
It is a shared effort by the industry to create innovation for container packaged, microservices based, dynamically scheduled applications and operations.
Prometheus has proven itself to be worthy to be an industry standard in alerting and monitoring.
It offers a wide-range of features,
from instrumenting to alerting,
and is supported by many other tools.
If you are looking for a monitoring tool,
definitely give it a shot!&lt;/p&gt;
</description>
        <pubDate>Fri, 23 Sep 2016 00:00:00 +0000</pubDate>
        <link>https://ordina-jworks.github.io/monitoring/2016/09/23/Monitoring-with-Prometheus.html</link>
        <guid isPermaLink="true">https://ordina-jworks.github.io/monitoring/2016/09/23/Monitoring-with-Prometheus.html</guid>
        
        <category>Prometheus</category>
        
        
        <category>Monitoring</category>
        
      </item>
    
      <item>
        <title>API Testing with Postman and Newman</title>
        <description>&lt;h3 id=&quot;prerequisites&quot;&gt;Prerequisites&lt;/h3&gt;
&lt;p&gt;For the purpose of this tutorial it is mandatory to have &lt;a href=&quot;https://www.getpostman.com/apps&quot; target=&quot;_blank&quot;&gt;Postman&lt;/a&gt; installed which is available has native apps for Windows, OS X and Linux. It is also mandatory to create an account at &lt;a href=&quot;https://www.algorithmia.com/&quot; target=&quot;_blank&quot;&gt;Algorithmia&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&quot;creating-and-selecting-an-environment&quot;&gt;Creating and selecting an environment&lt;/h3&gt;
&lt;p&gt;Postman’s environment functionality makes it very easy to switch between different environments. A set of variables can be configured per environment and when switching from one environment to another one these will be replaced accordingly. For example let’s create an environment called “production”.  Click the “No environment” dropdown in the header and select “Manage environments”.
&lt;br /&gt;
&lt;br /&gt;
&lt;img src=&quot;/img/postman-2016/manage_environment.png&quot; alt=&quot;Alt text&quot; /&gt;
&lt;br /&gt;
&lt;br /&gt;
Select the “Add” button on the popup that is presented to you.  Add &lt;code class=&quot;highlighter-rouge&quot;&gt;url https://api.algorithmia.com/v1/algo/&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;key simNz9pf7hfAQNifdA224K1GFhs1&lt;/code&gt;.  Don’t forget to replace the secret by your own key.
 &lt;br /&gt;
 &lt;br /&gt;
&lt;img src=&quot;/img/postman-2016/manage_environment_values.jpg&quot; alt=&quot;Alt text&quot; /&gt;
&lt;br /&gt;
&lt;br /&gt;
Finally select the “Production” environment in the environment dropdown and let’s create our first request.
&lt;br /&gt;
&lt;br /&gt;
&lt;img src=&quot;/img/postman-2016/manage_environment_production.png&quot; alt=&quot;Alt text&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;creating-a-post-request&quot;&gt;Creating a POST request&lt;/h3&gt;
&lt;p&gt;Enter &lt;code class=&quot;highlighter-rouge&quot;&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;{url&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;}/WayneS/Calculator/&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.1&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;/code&gt; in the request field and change the method from GET to POST.  We need to add some additional headers as well so add &lt;code class=&quot;highlighter-rouge&quot;&gt;Content-Type application/json&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;Authorization Simple {{key}}&lt;/code&gt;.  As you can see, we are using the environment variables &lt;code class=&quot;highlighter-rouge&quot;&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;{url&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;}&lt;/span&gt;&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;{key&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;}&lt;/span&gt;&lt;/code&gt; so when switching environments, those variables will get replaced.  The &lt;code class=&quot;highlighter-rouge&quot;&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;{...&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;}&lt;/span&gt;&lt;/code&gt; format can only be used in the request URL/URL params/Header values/form-data/url-encoded values/Raw body content/Helper fields.
&lt;br /&gt;
&lt;br /&gt;
&lt;img src=&quot;/img/postman-2016/request_headers.png&quot; alt=&quot;Alt text&quot; /&gt;
&lt;br /&gt;
&lt;br /&gt;
Postman also has a few dynamic variables which you can use. For example, &lt;code class=&quot;highlighter-rouge&quot;&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;{$guid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;}&lt;/span&gt;&lt;/code&gt; is generating a random v4 style guid, &lt;code class=&quot;highlighter-rouge&quot;&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;{$timestamp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;}&lt;/span&gt;&lt;/code&gt; is the current timestamp, &lt;code class=&quot;highlighter-rouge&quot;&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;{$randomInt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;}&lt;/span&gt;&lt;/code&gt; a random integer between 0 and 1000. More of those will be added in future releases. But for now, let us just simply enter &lt;code class=&quot;highlighter-rouge&quot;&gt;&quot;x=log(2)&quot;&lt;/code&gt; as the raw content of our request.
&lt;br /&gt;
&lt;br /&gt;
&lt;img src=&quot;/img/postman-2016/request_body.png&quot; alt=&quot;Alt text&quot; /&gt;
&lt;br /&gt;
&lt;br /&gt;
Finally let’s hit the “Send” button and if everything goes as expected, we should receive the following response.
&lt;br /&gt;
&lt;br /&gt;
&lt;img src=&quot;/img/postman-2016/request_send.jpg&quot; alt=&quot;Alt text&quot; /&gt;
&lt;br /&gt;
&lt;br /&gt;
Next we are going to write our test, but first let us save our request into a collection. By clicking on the create collection button on the collections tab, the following popup will be displayed.  Simply enter “Calculator” as the name of the collection and hit the create button.
&lt;br /&gt;
&lt;br /&gt;
&lt;img src=&quot;/img/postman-2016/create_collection.jpg&quot; alt=&quot;Alt text&quot; /&gt;
&lt;br /&gt;
&lt;br /&gt;
Now hit the “Save” button next to the request field. Enter “Log” as the name of the request and select “Calculator” from the dropdown menu.
&lt;br /&gt;
&lt;br /&gt;
&lt;img src=&quot;/img/postman-2016/request_save.jpg&quot; alt=&quot;Alt text&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;writing-a-test&quot;&gt;Writing a test&lt;/h3&gt;
&lt;p&gt;A Postman test is essentially JavaScript code which sets values for the special ‘tests’ object. To know which other objects and libraries are available while writing your test cases, make sure you check the following &lt;a href=&quot;https://www.getpostman.com/docs/sandbox&quot; target=&quot;_blank&quot;&gt;link&lt;/a&gt;. Let’s copy following code snippet in the Tests sandbox.
&lt;br /&gt;&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;tests[&lt;span class=&quot;s2&quot;&gt;&quot;Status code is 200&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; responseCode.code &lt;span class=&quot;o&quot;&gt;===&lt;/span&gt; 200;
var jsonData &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; JSON.parse&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;responseBody&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;;
tests[&lt;span class=&quot;s2&quot;&gt;&quot;Verify result&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; jsonData.result.x &lt;span class=&quot;o&quot;&gt;===&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;0.69314718056&quot;&lt;/span&gt;;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;&lt;br /&gt;
&lt;img src=&quot;/img/postman-2016/test.jpg&quot; alt=&quot;Alt text&quot; /&gt;
&lt;br /&gt;
&lt;br /&gt;
The test will run each time you hit the “Send” button. Let’s say we need a custom function to set some variables, this can easily be achieved in the pre-request sandbox as shown below:
&lt;br /&gt;
&lt;br /&gt;
&lt;img src=&quot;/img/postman-2016/custom_function.jpg&quot; alt=&quot;Alt text&quot; /&gt;
&lt;br /&gt;
&lt;br /&gt;
Here we are using the ‘postman’ object and are calling the setEnvironmentVariable function on it, this allows us to assign the result of our function to a variable on the environment scope for later use.&lt;/p&gt;

&lt;h3 id=&quot;collection-runner&quot;&gt;Collection Runner&lt;/h3&gt;
&lt;p&gt;Let’s assume we want to run several tests at once. Postman has a Collection Runner utility that allows us to just do that, even thousands of tests if we want. To access the runner click on “Runner” in the top header then select  “Calculator” as the collection and “Production” as the environment. We want the runner to do that 2 times so enter 2 in the iteration inputfield like shown in the screenshot below.
&lt;br /&gt;
&lt;br /&gt;
&lt;img src=&quot;/img/postman-2016/runner_full.jpg&quot; alt=&quot;Alt text&quot; /&gt;
&lt;br /&gt;
&lt;br /&gt;
Scroll down and hit the blue “Start Test” button. Following test report will be presented to you.
&lt;br /&gt;
&lt;br /&gt;
&lt;img src=&quot;/img/postman-2016/runner_result.jpg&quot; alt=&quot;Alt text&quot; /&gt;
&lt;br /&gt;
&lt;br /&gt;
Writing a request and tests for each different permutation of data could get tiresome and tedious. On the test runner screen we are given the option to choose a data file. This data file can be either a CSV or a JSON file, but will allow us to set up data in bulk to be run through the test runner. Create a new csv file and copy following snippet into it.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;input,expected_result
2,&quot;0.69314718056&quot;
224,&quot;5.41164605186&quot;
3000,&quot;8.00636756765&quot;
388949,&quot;12.8712035086&quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;We need to rewrite the body of our request so it will use the variable of our csv as follows.
&lt;br /&gt;
&lt;br /&gt;
&lt;img src=&quot;/img/postman-2016/request_csv.jpg&quot; alt=&quot;Alt text&quot; /&gt;
&lt;br /&gt;
&lt;br /&gt;
We also need to rewrite our test. Like you can see we use the ‘data’ object to call our expected_result variable.
&lt;br /&gt;
&lt;br /&gt;
&lt;img src=&quot;/img/postman-2016/test_csv.jpg&quot; alt=&quot;Alt text&quot; /&gt;
&lt;br /&gt;
&lt;br /&gt;
Back to the runner window. Select the “Calculator” collection and the “Production” environment. Click the “Choose Files” button and select the csv file you just created, click the “Preview” button to check for any inconsistenties. As there are 4 entries in our csv we want to use to feed our test enter 4 in the iteration inputfield.
&lt;br /&gt;
&lt;br /&gt;
&lt;img src=&quot;/img/postman-2016/runner_csv.jpg&quot; alt=&quot;Alt text&quot; /&gt;
&lt;br /&gt;
&lt;br /&gt;
Hit the “Start Test” button and you will now see 12 green tests. Pretty neat, isn’t it?
&lt;br /&gt;
&lt;br /&gt;
&lt;img src=&quot;/img/postman-2016/runner_result_csv.jpg&quot; alt=&quot;Alt text&quot; /&gt;
&lt;br /&gt;
&lt;br /&gt;&lt;/p&gt;

&lt;h3 id=&quot;newman&quot;&gt;Newman&lt;/h3&gt;
&lt;p&gt;Integrating Postman tests with build systems can easily be accomplished with Newman. Newman is the command line tool companion for Postman. It can be installed through the Node.js package manager, npm. You’ll find more information on how the install Newman &lt;a href=&quot;https://github.com/postmanlabs/newman&quot; target=&quot;_blank&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;After Newman is installed we can export our previously created collection and environment. Select the ‘Calculator’ collection and hit export and save as ‘my_collection.json’.
&lt;br /&gt;
&lt;br /&gt;
&lt;img src=&quot;/img/postman-2016/export_collection.jpg&quot; alt=&quot;Alt text&quot; /&gt;
&lt;br /&gt;
&lt;br /&gt;
To export the ‘Production’ environment select ‘Manage Environment’ and on the next popup hit export and save as ‘prod_environment.json’.
&lt;br /&gt;
&lt;br /&gt;
&lt;img src=&quot;/img/postman-2016/export_environment.jpg&quot; alt=&quot;Alt text&quot; /&gt;
&lt;br /&gt;
&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;Now run you test with Newman using following command where my_collection.json is the exported collection, my_data.csv the csv, prod_environment.json the environment and -n the number of lines from our csv.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;newman run my_collection.json -n 4 -d my_data.csv -e prod_environment.json
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;summary&quot;&gt;Summary&lt;/h3&gt;
&lt;p&gt;In this tutorial we saw how to create a request and a test. We saw how to create a collection and how to run it with the collection runnner and Newman.
I hope you enjoyed this tutorial and if you have any question feel free to add these as a comment or to email me at &lt;a href=&quot;mailto:gregory.rinaldi@ordina.be&quot;&gt;gregory.rinaldi@ordina.be&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&quot;useful-links&quot;&gt;Useful links&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.getpostman.com/docs/importing_swagger&quot; target=&quot;_blank&quot;&gt;Importing Swagger files&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.getpostman.com/slack-invite&quot; target=&quot;_blank&quot;&gt;Postman Slack invite&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.getpostman.com/docs/importing_curl&quot; target=&quot;_blank&quot;&gt;Importing cURL commands&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.getpostman.com/docs/creating_curl&quot; target=&quot;_blank&quot;&gt;Creating cURL commands&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.getpostman.com/docs/soap_requests&quot; target=&quot;_blank&quot;&gt;Making SOAP requests&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.getpostman.com/docs/newman_in_docker&quot; target=&quot;_blank&quot;&gt;Running Newman in Docker&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.getpostman.com/docs/helpers&quot; target=&quot;_blank&quot;&gt;Authentication helpers&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.getpostman.com/docs/creating_documentation&quot; target=&quot;_blank&quot;&gt;Publish Documentation for your Collections&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://blog.getpostman.com/2016/03/23/conditional-workflows-in-postman/&quot; target=&quot;_blank&quot;&gt;Conditional Workflows in Postman&lt;/a&gt; (work in progress)&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.npmjs.com/package/newman/&quot; target=&quot;_blank&quot;&gt;Newman&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;integrating_with_jenkins/&quot; target=&quot;_blank&quot;&gt;Integrating Newman with Jenkins &lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Fri, 16 Sep 2016 00:00:00 +0000</pubDate>
        <link>https://ordina-jworks.github.io/testing/2016/09/16/Automation-testing-with-postman.html</link>
        <guid isPermaLink="true">https://ordina-jworks.github.io/testing/2016/09/16/Automation-testing-with-postman.html</guid>
        
        <category>Postman</category>
        
        <category>Integration Testing</category>
        
        <category>Newman</category>
        
        <category>Automation</category>
        
        <category>Testing</category>
        
        
        <category>Testing</category>
        
      </item>
    
      <item>
        <title>Microservices Dashboard</title>
        <description>&lt;p&gt;&lt;img class=&quot;center-block&quot; alt=&quot;Architecture&quot; src=&quot;/img/microservices-dashboard/screenshot.png&quot; width=&quot;70%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;So you’ve jumped on the hype train, built a bunch of microservices, and got your first releases under your belt. 
Now what?
Our experiences taught us this is the easy part.
With the newly obtained microservices freedom, teams easily plunge into a world of cowboys and unicorns.
The big ball of mud is just around the corner.
Panic, mayhem and chaos loom over the organisation, waiting for everything to spin out of control.
Especially for any enterprise not residing in Silicon Valley, maintaining some sort of governance and compliancy is essential.&lt;/p&gt;

&lt;p&gt;What does a microservice architecture mean not just for the developers, but also for analysts and managers?
What can we as developers do to offer them peace of mind?&lt;/p&gt;

&lt;h3 id=&quot;managers-like-to-have-a-grip-on-things&quot;&gt;Managers like to have a grip on things&lt;/h3&gt;

&lt;p&gt;They want to get a sense of compliancy and maturity of the components part of the ecosystem.
In theory a microservices architecture gives developers complete freedom to use whatever tools and frameworks they want inside their microservice.
In practice, managers often want to slightly restrict that freedom to avoid complete chaos.
It’s not uncommon for managers and architects to impose a set of choices developers can choose from, and goals the teams have to achieve.
In order to facilitate recruitment and knowledge transfer, developers could be forced to choose between for instance Java or Javascript.
Similarly, architects might enforce every microservice to have a quality gate in place and to have a technical debt less than five days.&lt;/p&gt;

&lt;p&gt;Aside from the technical aspects inside a microservice, compliancy is even more crucial at the contract level.
They should be defined according to an architectural vision and comply to standards across the organisation.
Having the ability to track these compliancy regulations and quality assurances is a key enabler for management to push for technical excellence.
Too often managers are left clueless on how much effort is required to mature the architecture and which teams they have to chase.
Having a dashboard at their disposal indicating where a lack of compliancy and maturity needs their attention can help to ensure budget and priorities are in line with the architectural goals.&lt;/p&gt;

&lt;p&gt;Aside from compliancy and maturity, managers want some level of change management in place.
Oftentimes this is achieved through ticketing systems and cumbersome processes.
A microservice architecture goes hand in hand with devops, including full automation and decoupling.
In that respect, teams ought to be able to define their own release schedule as there is no need for a waterfall manual testing effort of months on end, and the impact on the ecosystem is contained and managed due to the decoupled nature of microservices.
Change management in a devops organisation is much more a read-model instead of a process-heavy model.
Managers want to know what is currently out there and what will be out there in the future.
This doesn’t require a manual ticketing system, simply a smart dashboard with a timeline.&lt;/p&gt;

&lt;h3 id=&quot;analysts-need-to-know-what-functionality-is-out-there&quot;&gt;Analysts need to know what functionality is out there&lt;/h3&gt;

&lt;p&gt;In order to reuse functionality and avoid duplication, functional analysts have a strong need for an overview of the current functional landscape.
Knowing which resources are exposed by what microservices, and which events and messages are being sent back and forth between microservices and queues, can go a long way in helping analysts understand the state of the architecture.&lt;/p&gt;

&lt;p&gt;Furthermore, impact analysis can significantly improve when an overview of components and how they are linked together is available to the analysts.
Not only does it encourage analysts to identify and inform consumers of a changing service, it can help to avoid introducing breaking changes due to negligence or ignorance.
During troubleshooting, testers and analysts should be able to find out what services and backends are involved in a certain functional flow.&lt;/p&gt;

&lt;p&gt;Just like managers, functional analysts are interested in upcoming features and releases.
On top of that, analysts can benefit from being able to define the future state of the ecosystem.
Especially when multiple teams are working on similar functionality, it can be notoriously difficult to avoid duplication and breaches of bounded contexts.
Using a dashboard to define what is coming up, can help to give them an unambiguous view of the current and future landscape.&lt;/p&gt;

&lt;h3 id=&quot;developers-can-benefit-from-a-broader-view-as-well&quot;&gt;Developers can benefit from a broader view as well&lt;/h3&gt;

&lt;p&gt;In a devops organisation, developers have the responsibility to not only build but also run their services.
Knowing which versions are deployed where, can assist developers in verifying whether their deployments are successful, but also to determine the versions of their dependencies.&lt;/p&gt;

&lt;p&gt;A graphical dashboard can go a long way in providing clarity to developers.
But most of all, it can act as a hub for other tools and documentation available.
Integrations can be made with for instance API documentation, performance tooling, service registries, in-depth instance-specific dashboards and perhaps even reactive insights.&lt;/p&gt;

&lt;h2 id=&quot;the-introduction-of-the-microservices-dashboard&quot;&gt;The introduction of the Microservices Dashboard&lt;/h2&gt;

&lt;p&gt;Visualising the state of the architecture and dependencies in the system can be a huge benefit to all stakeholders in the IT organisation.
The Microservices Dashboard is a brand new open source project, which officially launched its first major release at Spring One Platform.
Building on top of Spring Boot and Spring Cloud, it visualises your microservice architecture and integrates with tools every microservice architecture benefits from.
This ranges from consumer-driven-contract testing over service discovery to hypermedia traversal and more.&lt;/p&gt;

&lt;p&gt;Microservices Dashboard is a simple application to visualize links between microservices and the encompassing ecosystem.
This AngularJS application consumes endpoints exposed by its server component.
It displays four columns: UI, Resources, Microservices and Backends.
Each of these columns show nodes and links between them.
The information for these links come from Spring Boot Actuator health endpoints, Pact consumer-driven-contract tests and hypermedia indexes, which are aggregated in the microservices-dashboard-server project.&lt;/p&gt;

&lt;h2 id=&quot;the-architecture&quot;&gt;The architecture&lt;/h2&gt;

&lt;p&gt;&lt;img class=&quot;center-block&quot; alt=&quot;Architecture&quot; src=&quot;/img/microservices-dashboard/architecture.png&quot; width=&quot;50%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The dashboard currently consists out of an AngularJS 1.x application which communicates over HTTP to a Spring Boot application.
The frontend uses D3.js to visualise the nodes in the four columns.
We are currently in the process of completely rebuilding the frontend stack.
Next version will be running on Angular 2, Typescript and EcmaScript 6.
Most of D3.js will be taken care of by Angular 2 itself.&lt;/p&gt;

&lt;p&gt;Thanks to this refactor we’ll see the introduction of RxJS, making the frontend much more reactive in nature.
This aligns our frontend and backend components goals, since the backend is already running RxJava.
Our efforts currently focus on replicating all functionalities currently available in the dashboard, albeit with much more attention to quality and testing.
Subsequently new features and enhancements will be built on top of a much more mature and extendible frontend application.&lt;/p&gt;

&lt;p&gt;Our server component is powered by Spring Boot’s auto configuration.
It’s a library which, once on the classpath of a regular Spring Boot application, will automatically transform the Spring Boot application into a JSON graph-serving engine.
It does so by using aforementioned RxJava.
The idea of the server application is that it will fetch information from the microservices ecosystem, with for instance Spring Cloud’s integration of service registries, and collect details of components and their relation within said ecosystem.
Needless to say collecting this information requires a lot of outbound calls, and can pose a serious performance burden in case the landscape gets bigger.
Making intelligent use of the system’s resources is absolutely necessary, and RxJava does just that.
In the future we might migrate to &lt;a href=&quot;https://projectreactor.io/&quot;&gt;Spring’s Reactor&lt;/a&gt; which has a more formal integration of the ReactiveX specification and better integration with Spring itself.
Once the frontend’s revamp is completed, the last step towards an end-to-end reactive flow is the HTTP connection between both components.
Currently the server still converts the Observable to blocking, undoing a lot of the performance gains we could achieve.
Yet even while eventually blocking, we’ve benchmarked a thirty percent performance gain in switching from CompletableFutures to Observables thanks to the more sustained async handling.&lt;/p&gt;

&lt;p&gt;Aside from its reactive nature, the server component of the dashboard is also built in a very pluggable way.
Information is retrieved from the ecosystem through so-called aggregators.
Currently four aggregators are provided: the health-indicators aggregator, the index aggregator, the mappings aggregator and the Pact aggregator.
We’re looking into supporting Spring Cloud’s recent addition, Spring Cloud Contract, as a source for aggregation.
New aggregators can be easily added, and all existing aggregators can be overridden, extended, turned on and off.
In the next section we’ll go through these aggregators and their purpose.&lt;/p&gt;

&lt;h2 id=&quot;collecting-information-from-the-ecosystem&quot;&gt;Collecting information from the ecosystem&lt;/h2&gt;

&lt;p&gt;The dashboard on its own doesn’t really make a lot of sense when it’s not connected to the architecture it’s supposed to visualise.
Aggregators pull in information which eventually gets translated into nodes and links on the dashboard.&lt;/p&gt;

&lt;h4 id=&quot;health-indicators-aggregator&quot;&gt;Health-indicators aggregator&lt;/h4&gt;

&lt;p&gt;Spring Boot exposes production-ready endpoints through its Actuator module.
The health endpoint returns information regarding the current health status of the application.
The source of this information is a bunch of health indicators, describing various components and dependencies of the application.
For instance, an application can have a dependency on a database, for which a health indicator will usually provide health information to the health endpoint, indicating whether the database is up and the connection pool hasn’t been depleted.&lt;/p&gt;

&lt;p&gt;Hence, health indicators describe an up-to-date relationship between the application they run on and its dependencies.
Spring Cloud ensures health indicators are automatically enabled when you are using service discovery, circuit breakers, a config server or other Spring Cloud services. However, health indicators don’t automatically describe a relationship between an application and another application it calls.
Luckily Spring Boot has a very easy way of adding custom health indicators.
As such, developers can add a health indicator the moment a remote service call is added to the application.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;What about real-time?&lt;/strong&gt;&lt;/p&gt;

  &lt;p&gt;Using health indicators we are certain the application calls another application programmatically.
This provides clarity in terms of the calls in the code and therefore the dependencies that exist across the applications.
However, using this method we aren’t sure whether this remote call is actually being executed at runtime.
These concerns are currently provided by other tools such as Twitter’s Zipkin.
In the future we will integrate the dashboard with real-time traffic information from Zipkin or similar tooling.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h4 id=&quot;index-aggregator&quot;&gt;Index aggregator&lt;/h4&gt;

&lt;p&gt;REST over HTTP is arguably the most popular communicational style in microservices architectures.
Therefore, gathering information on where and how REST is used can be quite useful.
Index and mappings aggregators perform this specific task, albeit each in a different way.&lt;/p&gt;

&lt;p&gt;The index aggregator relies on a subconstraint of REST called HATEOAS.
It stands for Hypermedia As The Engine Of Application State, and describes the idea of adding links in the payload of responses to other resources.
This enables discovery of resources, much like we are using the world wide web from its inception.
It prevents the need to bookmark URIs to resources, decoupling implementations and enabling independent evolution of the service.&lt;/p&gt;

&lt;p&gt;Similarly to a regular website, REST APIs using HATEOAS require a homepage or index from which the resource discovery starts.
Simply creating an index resource with links to the other resources the service provides, and exposing this index resource at the root of the application takes care of this.
Spring HATEOAS provides useful tools to add links to resources.&lt;/p&gt;

&lt;p&gt;Once every microservice has an index resource, we can use service discovery to discover all the services, and fetch all the index resources to map out the landscape of resources.
This is an excellent source for the dashboard, as it shows the relation between microservices and the RESTful resources they expose.&lt;/p&gt;

&lt;h4 id=&quot;mappings-aggregator&quot;&gt;Mappings aggregator&lt;/h4&gt;

&lt;p&gt;Oftentimes, RESTful resources are exposed in a more traditional way (using REST level 2) without the added complexity of HATEOAS.
While this is not fully REST compliant, it is most common among APIs using JSON over HTTP.
Spring Boot offers a handy endpoint in their Actuator module, called the mappings endpoint.
It describes all the resources exposed by the application when Spring MVC REST is used.
While also describing Spring’s own resources, a simple filter allows us to deduct node and link information from these endpoints to visualise in the dashboard.&lt;/p&gt;

&lt;h4 id=&quot;pact-aggregator&quot;&gt;Pact aggregator&lt;/h4&gt;

&lt;p&gt;In a microservices architecture, testing is absolutely crucial.
As the primary benefit of microservices is faster time-to-market, changes happen all the time.
Not only unit and integration testing is required, but also more advanced contract testing to act as a safety net.
Consumer-driven-contract testing allows the consumer (the client) to define what he expects from the producer (the service), and ensure the producer validates that definition every time a change is made to the service.
This allows the consumer to rest at ease, knowing the producer will remain backwards compatible or version accordingly, and gives the producer knowledge of who uses exactly which parts of its service.
The latter gives the producer the chance to request consumers to update their service in case they are causing too much complexity on the producer’s side due to backwards compatibility.&lt;/p&gt;

&lt;p&gt;Tests like these document with guaranteed certainty relations between clients and services or services and services.
Querying the contracts that define these relations offer a great source of information for the dashboard’s nodes and links between them.
When working with the consumer-driven-contract testing framework Pact, a repository called the Pact-broker holds all the available contracts and exposes them through a REST interface.
Our Pact aggregator makes use of this interface to pull the information into the dashboard.&lt;/p&gt;

&lt;p&gt;Spring Cloud recently added the Spring Cloud Contract module to their portfolio, based on Accurest.
We’re planning to integrate the Microservices Dashboard with Spring Cloud Contract in the near future as well.&lt;/p&gt;

&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;The Microservices Dashboard gives managers, analysts and developers peace of mind when working in a microservices architecture.
Not only does it map relations between components in a visually attractive manner, it can also be a great tool for compliancy, change management, functional analysis and troubleshooting.&lt;/p&gt;

&lt;p&gt;The dashboard is currently at version 1.0.1, and can be downloaded through maven central.
To quickly get up and running, make sure to check out the &lt;a href=&quot;http://ordina-jworks.github.io/microservices-dashboard/1.0.1/&quot;&gt;reference documentation&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Since the project is still fairly new, any feedback is greatly appreciated.
You can reach us through &lt;a href=&quot;https://gitter.im/ordina-jworks/microservices-dashboard&quot;&gt;Gitter&lt;/a&gt; or &lt;a href=&quot;https://github.com/ordina-jworks/microservices-dashboard&quot;&gt;GitHub&lt;/a&gt;.&lt;/p&gt;
</description>
        <pubDate>Mon, 12 Sep 2016 00:00:00 +0000</pubDate>
        <link>https://ordina-jworks.github.io/microservices/2016/09/12/Microservices-Dashboard-1.0.1.html</link>
        <guid isPermaLink="true">https://ordina-jworks.github.io/microservices/2016/09/12/Microservices-Dashboard-1.0.1.html</guid>
        
        <category>Microservices</category>
        
        <category>Dashboard</category>
        
        <category>Spring</category>
        
        <category>Spring Boot</category>
        
        <category>RxJava</category>
        
        <category>Pact</category>
        
        <category>Hypermedia</category>
        
        <category>Hateoas</category>
        
        
        <category>Microservices</category>
        
      </item>
    
      <item>
        <title>SpringOne Platform</title>
        <description>&lt;blockquote&gt;
  &lt;p&gt;&lt;a href=&quot;https://springoneplatform.io/&quot;&gt;SpringOne Platform&lt;/a&gt; is the successor of &lt;a href=&quot;https://springoneplatform.io/2015&quot;&gt;SpringOne 2GX&lt;/a&gt;, with a focus mainly on &lt;a href=&quot;https://spring.io&quot;&gt;Spring&lt;/a&gt; and &lt;a href=&quot;https://www.cloudfoundry.org/&quot;&gt;Cloud Foundry&lt;/a&gt;. Next to these technical topics, SpringOne Platform also offered many sessions on cultural transformation and DevOps. Cultural transformation and DevOps are key to deliver meaningful solutions more quickly. This can be achieved by creating empowered teams, able to make independent decisions. To implement these collaborative teams, leadership buy-in is hugely important. Getting away from legacy thinking will allow enterprises to obtain short feedback cycles and thus continuously improve.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;from-imperative-to-reactive-web-apps---rossen-stoyanchev&quot;&gt;From Imperative To Reactive Web Apps - Rossen Stoyanchev&lt;/h2&gt;

&lt;p&gt;The marquee feature of Spring 5, will be first class support for Reactive Web applications. Reactive programming is about non-blocking, event-driven applications with &lt;a href=&quot;http://www.reactivemanifesto.org/glossary#Back-Pressure&quot;&gt;back-pressure&lt;/a&gt;. Back-pressure helps to ensure a good collaboration between producers and consumers. The &lt;a href=&quot;http://www.reactivemanifesto.org/&quot;&gt;Reactive Manifesto&lt;/a&gt; is an interesting read on this topic.&lt;/p&gt;

&lt;p&gt;To support reactive, Spring 5 will use &lt;a href=&quot;http://projectreactor.io/&quot;&gt;Project Reactor&lt;/a&gt; (led by Stéphane Maldini) through the &lt;a href=&quot;https://github.com/spring-projects/spring-framework/tree/master/spring-web-reactive&quot;&gt;Spring Web Reactive&lt;/a&gt; project. This &lt;a href=&quot;https://spring.io/blog/2016/07/28/reactive-programming-with-spring-5-0-m1&quot;&gt;blogpost&lt;/a&gt;, by Rossen Stoyanchev is a nice starting point to learn about &lt;a href=&quot;https://projectreactor.io/core/docs/api/reactor/core/publisher/Flux.html&quot;&gt;Flux&lt;/a&gt;, &lt;a href=&quot;https://projectreactor.io/core/docs/api/reactor/core/publisher/Mono.html&quot;&gt;Mono&lt;/a&gt; and the Spring Reactive world.&lt;/p&gt;

&lt;h2 id=&quot;managing-secrets-at-scale---mark-paluch&quot;&gt;Managing Secrets at Scale - Mark Paluch&lt;/h2&gt;
&lt;p&gt;In a world, where we run large amounts of microservices in orchestrated containers, we can never forget about security, encrypting passwords, storing keys, rotating secrets, etc. Today, applications consume both first and third party APIs and need authentication and authorization to do this in a safe way. Traditional patterns cannot keep the security bar high with dynamic deployment scenarios.&lt;/p&gt;

&lt;p&gt;As a &lt;a href=&quot;https://www.ordina.be/en/services-et-solutions/themas/secure-by-design/&quot;&gt;Secure-By-Design&lt;/a&gt; company, this talk immediately caught my attention. In a Spring world, we can use &lt;a href=&quot;https://github.com/spring-cloud-incubator/spring-cloud-vault-config&quot;&gt;Spring Cloud Vault Config&lt;/a&gt;, wrapping &lt;a href=&quot;https://www.vaultproject.io/&quot;&gt;Vault&lt;/a&gt;. An interesting tutorial on this Spring library is available on &lt;a href=&quot;https://spring.io/blog/2016/06/24/managing-secrets-with-vault&quot;&gt;spring.io&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Slides from the talk are available &lt;a href=&quot;https://t.co/ye2EoeO1tJ&quot;&gt;online&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;its-not-you-its-us-winning-over-people-for-yourself-and-the-team---neha-batra&quot;&gt;It’s not you, it’s us: Winning over people for yourself and the team - Neha Batra&lt;/h2&gt;

&lt;p&gt;This was one of the non-technical talks, but aimed to help with the daily management of technical projects. Neha’s session was the most interactive one I attended at SpringOne Platform: about 10 minutes in the session, she wanted us to pair to do a personal SWOT analysis with a stranger in the room and see how we can learn from each other. Everyone participated and I believe this might actually be useful in the context of a project. Something to try out!&lt;/p&gt;

&lt;p&gt;She ended her session with a tool chest to prevent and mitigate issues as they come up:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;SWOT analysis&lt;/li&gt;
  &lt;li&gt;Personal goals&lt;/li&gt;
  &lt;li&gt;Inception&lt;/li&gt;
  &lt;li&gt;Set schedule / cadence&lt;/li&gt;
  &lt;li&gt;Provide feedback&lt;/li&gt;
  &lt;li&gt;Provide a “safe haven”&lt;/li&gt;
  &lt;li&gt;Collect and discuss concerns&lt;/li&gt;
  &lt;li&gt;Talk in person&lt;/li&gt;
  &lt;li&gt;Write down useful conversations&lt;/li&gt;
  &lt;li&gt;Find a way to align first (eg. TDD + pair programming)&lt;/li&gt;
  &lt;li&gt;Daily retros&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The slidedeck of her talk is available on &lt;a href=&quot;http://www.slideshare.net/NehaBatra5/its-not-you-its-us-winning-over-people-for-yourself-and-the-team&quot;&gt;Slideshare&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;the-five-stages-of-cloud-native---casey-west&quot;&gt;The five stages of Cloud Native - Casey West&lt;/h2&gt;

&lt;p&gt;&lt;img class=&quot;float-image p-image&quot; src=&quot;/img/s1p/casey-west.jpg&quot; alt=&quot;Casey West&quot; style=&quot;width: 100px&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Another non-technical talk, from the talented and funny Casey West, on how companies are adopting the &lt;strong&gt;Cloud Native&lt;/strong&gt; approach to software development.
The talk was very entertaining and resonated with the audience to such an extent, that there was constantly someone laughing. The slides itself don’t say much without explanation so I’ll try to clarify them a bit here.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Analogous to the &lt;a href=&quot;https://en.wikipedia.org/wiki/K%C3%BCbler-Ross_model&quot;&gt;Kübler-Ross model&lt;/a&gt;, there are five stages when adopting Cloud Native development&lt;/strong&gt;:&lt;/p&gt;

&lt;h3 id=&quot;denial&quot;&gt;Denial&lt;/h3&gt;

&lt;p&gt;&lt;a href=&quot;https://twitter.com/caseywest&quot;&gt;@caseywest&lt;/a&gt; immediately grasps the crowd’s attention with these very familiar quotes:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;“Containers are just tiny virtual machines”&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;No they’re not. Stop treating them as such. Moving a huge application or database from a virtual machine to a container doesn’t really solve anything.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;“We don’t need to automate Continuous Delivery because we already automate our infrastructure with Puppet”&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;The problem is that these measures are not enough and &lt;strong&gt;they don’t solve enough of the problem&lt;/strong&gt;. Managing infrastructure and deploying applications using Puppet scripts already is a great improvement by treating &lt;em&gt;Infrastructure as Code&lt;/em&gt; but it &lt;strong&gt;still requires too much manual labour&lt;/strong&gt;.&lt;/p&gt;

&lt;h3 id=&quot;anger&quot;&gt;Anger&lt;/h3&gt;

&lt;p&gt;Again, the goal of these funny quotes is prove a very valid point:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;“It works on my machine”&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;The following quote isn’t in the slides but might also sound familiar:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;“Let me do a hotfix, I can figure it out”&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;and my favourite:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;“DEV is just YOLO-ing sh#t to production”&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;These illustrate the problems, you are likely to get when trying to develop Cloud Native applications without the proper culture in place.
This is a &lt;strong&gt;clear breakdown in communication&lt;/strong&gt; and is more a &lt;em&gt;people problem&lt;/em&gt; than an IT problem.
It just doesn’t work, especially when also considering the compliance or legal aspect. There is a &lt;strong&gt;lack of acknowledgement&lt;/strong&gt; that we need roles and responsibilities.&lt;/p&gt;

&lt;h3 id=&quot;bargaining&quot;&gt;Bargaining&lt;/h3&gt;

&lt;blockquote&gt;
  &lt;p&gt;“What if we create microservices that all talk to the same datasource?”&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Single data model and data ownership are not possible this way.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;“We crammed this monolith in a container and called it a microservice”&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Applications need to adhere to some restrictions to run and scale in the cloud, otherwise you cannot take advantage of the benefits of a platform.
Often, there also is the notion of something called &lt;strong&gt;bi-modal IT&lt;/strong&gt;.
This is basically dividing your company up into &lt;strong&gt;sad mode&lt;/strong&gt; vs &lt;strong&gt;awesome mode&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;A lot of organizations believe &lt;strong&gt;they don’t need to change&lt;/strong&gt; and prefer to stay in sad mode, they use &lt;strong&gt;bi-modal IT&lt;/strong&gt; as an excuse. Honestly, nobody really wants to work in sad mode.&lt;/p&gt;

&lt;h3 id=&quot;depression&quot;&gt;Depression&lt;/h3&gt;

&lt;p&gt;Once people actually start creating Cloud Native applications, the depression kicks in:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;“We created 200 microservices and forgot to setup Jenkins”&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;A common mistake is &lt;strong&gt;not&lt;/strong&gt; to go for a fully automated CI/CD pipeline from the start.
This should be your first action when you start a new project. It is necessary to &lt;strong&gt;automate your path to production&lt;/strong&gt;.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;“We have an automated build pipeline but release twice a year”&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;When business is not on board with rapid, iterative delivery, you will never get the desired fast feedback loops.&lt;/p&gt;

&lt;h3 id=&quot;acceptance&quot;&gt;Acceptance&lt;/h3&gt;

&lt;p&gt;Finally, everyone start realizing the painful, but obvious truth:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;All software sucks&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;by which he means that creating software is not easy and will never become easy. But we can try to make it as easy as possible for ourselves.&lt;/p&gt;

&lt;p&gt;Casey also advises us to &lt;a href=&quot;https://en.wikipedia.org/wiki/CAP_theorem&quot;&gt;respect the CAP theorem&lt;/a&gt;, respect &lt;a href=&quot;https://en.wikipedia.org/wiki/Conway%27s_law&quot;&gt;Conway’s Law&lt;/a&gt; and &lt;strong&gt;automate everything&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;Also, don’t expect to get all of these things right from the start. Taking baby steps and improving gradually over time is certainly possible. An example is to put a monolith inside a container and start breaking it up into more manageable pieces.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&amp;amp;TLDR;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/s1p/operability.jpg&quot; alt=&quot;Casey West&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The (very pretty) slides can be found on &lt;a href=&quot;http://www.slideshare.net/Pivotal/the-five-stages-of-cloud-native&quot;&gt;Slideshare&lt;/a&gt;.&lt;/p&gt;

&lt;h1 id=&quot;ordina&quot;&gt;Ordina&lt;/h1&gt;

&lt;p&gt;&lt;a href=&quot;https://ordina.be&quot;&gt;Ordina&lt;/a&gt; was represented at SpringOne Platform with 2 speakers and 3 talks:&lt;/p&gt;

&lt;h3 id=&quot;writing-your-own-spring-boot-starter---dieter-hubau&quot;&gt;Writing your own Spring Boot Starter - Dieter Hubau&lt;/h3&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/Turbots&quot;&gt;Dieter Hubau&lt;/a&gt; gave a very nice introduction on how to write your own &lt;a href=&quot;https://github.com/spring-projects/spring-boot/tree/master/spring-boot-starters&quot;&gt;Spring Boot Starter&lt;/a&gt;. A Spring Boot Starter is the de-facto standard tool for starting with a greenfield Spring project. He started by explaining the magic behind Spring Boot Starters (and &lt;a href=&quot;http://docs.spring.io/spring-boot/docs/current/reference/html/using-boot-auto-configuration.html&quot;&gt;@AutoConfiguration&lt;/a&gt;) and ended with a cool game of Josh Long Pokemon, deployed on Cloud Foundry.&lt;/p&gt;

&lt;p&gt;His slides are available &lt;a href=&quot;http://www.slideshare.net/SpringCentral/writing-your-own-spring-boot-starter&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&quot;writing-comprehensive-and-guaranteed-up-to-date-rest-api-documentation---andreas-evers&quot;&gt;Writing Comprehensive and Guaranteed Up-to-date REST API Documentation - Andreas Evers&lt;/h3&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/andreasevers&quot;&gt;Andreas Evers&lt;/a&gt; talked about &lt;a href=&quot;http://projects.spring.io/spring-restdocs/&quot;&gt;Spring REST Docs&lt;/a&gt; to generate documentation that is always up to date. To achieve this, a test-driven approach can be used: generate snippets from integration tests. Combine these snippets with manually written templates and finally generate HTML. Personally, I have always been a huge fan of “documentation-as-code” and Spring REST Docs is a great tool to achieve this goal.&lt;/p&gt;

&lt;p&gt;His slides are available &lt;a href=&quot;https://speakerdeck.com/andreasevers/writing-comprehensive-and-guaranteed-up-to-date-rest-api-documentation-springone-platform-2016&quot;&gt;here&lt;/a&gt;. This &lt;a href=&quot;https://ordina-jworks.github.io/conference/2016/06/30/SpringIO16-Spring-Rest-Docs.html&quot;&gt;blogpost&lt;/a&gt; by &lt;a href=&quot;https://ordina-jworks.github.io/author/kevin-van-houtte/&quot;&gt;Kevin Van Houtte&lt;/a&gt; provides more insight and examples on Spring REST Docs.&lt;/p&gt;

&lt;h3 id=&quot;ignite-microservices-dashboard---andreas-evers&quot;&gt;Ignite: Microservices Dashboard - Andreas Evers&lt;/h3&gt;
&lt;p&gt;On Monday evening, Andreas pitched the &lt;a href=&quot;https://github.com/ordina-jworks/microservices-dashboard&quot;&gt;Ordina Microservices Dashboard&lt;/a&gt; that was released a couple of hours earlier. The Ordina Microservices Dashboard left a big impression:&lt;/p&gt;

&lt;p&gt;&lt;img width=&quot;400&quot; alt=&quot;Microservices Dashboard&quot; src=&quot;/img/s1p/msd.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Definitely worth checking out. Expect an in-depth blogpost here soon!&lt;/p&gt;

&lt;h2 id=&quot;simplifying-the-future---adrian-cockroft&quot;&gt;Simplifying the Future - Adrian Cockroft&lt;/h2&gt;

&lt;p&gt;The closing keynote at SpringOne Platform was reserved for one of the most influential people in our industry: &lt;a href=&quot;https://www.linkedin.com/in/adriancockcroft&quot;&gt;Adrian Cockcroft&lt;/a&gt;. Always at the edge of technology, Adrian often is credited with making Microservices a mature and useful architectural pattern. His talk focussed on:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Simplifying work&lt;/li&gt;
  &lt;li&gt;Simplify the organization&lt;/li&gt;
  &lt;li&gt;Simplify things we build&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;I really recommend watching &lt;a href=&quot;https://www.youtube.com/watch?v=DGK6jjamzfY&quot;&gt;his entire presentation&lt;/a&gt; on YouTube.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/s1p/main.png&quot; alt=&quot;Main&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/s1p/panel.png&quot; alt=&quot;Panel&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/s1p/adrian.png&quot; alt=&quot;Adrian&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/s1p/vegas.png&quot; alt=&quot;Vegas&quot; /&gt;&lt;/p&gt;
</description>
        <pubDate>Tue, 09 Aug 2016 00:00:00 +0000</pubDate>
        <link>https://ordina-jworks.github.io/conferences/2016/08/09/s1p.html</link>
        <guid isPermaLink="true">https://ordina-jworks.github.io/conferences/2016/08/09/s1p.html</guid>
        
        <category>Security</category>
        
        <category>Spring</category>
        
        <category>CloudFoundry</category>
        
        <category>Las Vegas</category>
        
        <category>Cloud</category>
        
        <category>Pivotal</category>
        
        
        <category>Conferences</category>
        
      </item>
    
      <item>
        <title>A web of trusted commits</title>
        <description>&lt;h2 id=&quot;who-do-you-trust&quot;&gt;Who Do You Trust?&lt;/h2&gt;
&lt;p&gt;When you’re building software with people from around the world, it’s important to validate that commits and tags are coming from an identified source. By using a distributed revision control system like Git, anyone can have an offline copy of your project’s code repository. In theory having a central repository is not necessary, but it can be used to provide an “official” source from which other developers can clone from and work on. These other floating repositories may contain malicious code because, unfortunately, it is remarkably easy to fake your identity when committing code using Git.&lt;/p&gt;

&lt;p&gt;The following command allows any individual with bad intentions to commit (malicious) code under your name, meaning that you will get the blame for the backdoor or exploit “you” committed:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;  &lt;span class=&quot;c&quot;&gt;# Individual commit.
&lt;/span&gt;
  &lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;git commit -a -m &lt;span class=&quot;s2&quot;&gt;&quot;a message&quot;&lt;/span&gt; --author &lt;span class=&quot;s2&quot;&gt;&quot;Sherlock H. &amp;lt;sherlock.h@bakerstreet.org&amp;gt;&quot;&lt;/span&gt;

  &lt;span class=&quot;c&quot;&gt;# Global settings.
&lt;/span&gt;
  &lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;git config --global user.name &lt;span class=&quot;s1&quot;&gt;'Sherlock H.'&lt;/span&gt;
  &lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;git config --global user.email sherlock.h@bakerstreet.org
  &lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;h2 id=&quot;ensuring-trust&quot;&gt;Ensuring Trust&lt;/h2&gt;

&lt;p&gt;This blog post tells the story of Sherlock H. Sherlock is a witty developer who holds any security-related topic very close to his heart. After a fair amount of pondering about how he could solve the problem of black-hearted developers impersonating his personality, he decided to add &lt;strong&gt;a Digital Signature&lt;/strong&gt; to his commits. By adding a signature Sherlock can finally sleep soundly at night because the signature indicates that he really issued the commit and that it has not been tampered with since he sent it. Moreover it can be used to trace the origin of malicious code that has made its way into a repository. The signature also assures non-repudiation, meaning that it becomes difficult for the signer to deny having signed something because the Digital Signature is unique to both the commit and the signer, and binds them together. Sherlock can now wholeheartedly vouch for the commit.&lt;/p&gt;

&lt;p&gt;Consider the following scenario:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Sherlock wants to send an urgent message to his fellow developer John W. telling that their application has been compromised by Jim M, a criminal mastermind who only has unkind intentions. John wants the guarantee that the message he received is sent by Sherlock and has not been tampered with by Jim.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;In order to securely exchange messages, both Sherlock and John will make use of their &lt;strong&gt;Key Pairs&lt;/strong&gt;. A Key Pair consists of a &lt;strong&gt;Public and Private Key&lt;/strong&gt; which are two unique mathematically related cryptographic keys. As its name suggests, the Public Key is made available to everyone by handing out copies or sharing them through a publicly accessible repository. The Private Key however must be kept confidential to its respective owner.&lt;/p&gt;

&lt;p&gt;Sherlock and John can do the following with the use of their Key Pair:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Signing&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;The message is still readable to everyone.&lt;/li&gt;
      &lt;li&gt;Guarantee of the sender’s identity (aka Sherlock).&lt;/li&gt;
      &lt;li&gt;Guarantee that the message has not been tampered with since it has been signed by the sender (aka Sherlock).&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Encryption&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;The message is only readable by the designated recipient (aka John).&lt;/li&gt;
      &lt;li&gt;No guarantee of the sender’s identity (aka Sherlock).&lt;/li&gt;
      &lt;li&gt;Encryption can be done &lt;strong&gt;symmetrically&lt;/strong&gt; by using a Shared Secret Key, a single key is then used for both encryption and decryption. &lt;strong&gt;Asymmetrical&lt;/strong&gt; encryption (aka Public Key encryption) with a Public/Private Keypair uses one key for encryption and another for decryption. Note that the advantages and challenges of using either encryption type is beyond the scope of this blog post.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;enforcing-trust&quot;&gt;Enforcing Trust&lt;/h2&gt;

&lt;p&gt;Sherlock will combine a digital signature with encryption to convince John that his message is trustworthy.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;Sherlock wants to send the following message to John: &lt;code class=&quot;highlighter-rouge&quot;&gt;Data! Data! Data! I can’t make bricks without clay.&lt;/code&gt;. He calculates the &lt;strong&gt;Hash&lt;/strong&gt; of this message by applying a publicly known hashing algorithm to the message. The calculated hash by using the SHA-256 hashing algorithm is &lt;code class=&quot;highlighter-rouge&quot;&gt;d6ba26816599a75310c4c263126d4b44979c7026f90e1db8e9b317d6658f3811&lt;/code&gt;. The hash value is unique to the hashed data.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Sherlock encrypts the Hash with his Private Key. This encrypted Hash together with a certificate containing additional information about the sender forms the Digital Signature. The reason why the Hash is encrypted and not the entire message, is that a hash function can convert an arbitrary input into a fixed length value which is usually much shorter than the original message. This saves time since hashing is much faster than signing.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Sherlock sends the original message and its Digital Signature to John.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;John receives the message and Digital Signature.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Whatever is encrypted with a Public Key can only be decrypted by using its corresponding Private Key and vice versa. Therefore John uses Sherlock’s Public Key to decrypt the Signature.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;John also re-calculates the Hash of the original message by applying the same hashing algorithm as Sherlock.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;John compares the Hash he calculated himself and the decrypted Hash received with Sherlock’s message.
If they’re identical he knows the message has not been tampered with during transit.
Should the message been compromised by Jim, then John would have calculated a different Hash than the encrypted Hash that Sherlock has sent along with his message.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;img class=&quot;center-block&quot; alt=&quot;Digital Signature&quot; src=&quot;/img/web-of-trusted-commits/digital_signature.png&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;creating-an-identity&quot;&gt;Creating An Identity&lt;/h2&gt;

&lt;p&gt;In order to sign his commits, Sherlock decided to use &lt;strong&gt;Gnu Privacy Guard (GPG)&lt;/strong&gt; as his weapon of choice. GPG is a complete and free implementation of the OpenPGP standard. It allows to encrypt and sign data and communication, features a versatile key management system as well as access modules for all kinds of public key directories.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Download and install GPG from the &lt;a href=&quot;https://www.gnupg.org/download/&quot;&gt;official website&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Open a command prompt&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;      &lt;span class=&quot;c&quot;&gt;# Generate a new Key Pair.
&lt;/span&gt;
      &lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;gpg --gen-key
      &lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Sherlock accepted the default &lt;code class=&quot;highlighter-rouge&quot;&gt;RSA and RSA&lt;/code&gt; key. RSA is a widely-used asymmetric encryption algorithm and is named after Ron Rivest, Adi Shamir and Len Adleman who invented it in 1977. Should you be interested in more mathematical details how this algorithm works, I can highly recommend watching &lt;a href=&quot;https://www.youtube.com/watch?v=wXB-V_Keiu8&quot;&gt;“Public Key Cryptography: RSA Encryption Algorithm”&lt;/a&gt; on YouTube.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Enter the desired key size. I recommend the &lt;code class=&quot;highlighter-rouge&quot;&gt;maximum key size of 4096 bits&lt;/code&gt; because they provide far better long-term security. While the default of 2048 bits is secure now, it won’t be in the future. 1024 bit keys are already considered within the range of being breakable and while technology advances 2048 bit keys will also become breakable. Eventually 4096 bit keys will be broken too, but that will be so far in the future that better encryption algorithms will also likely have been developed by then.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Sherlock accepted the &lt;code class=&quot;highlighter-rouge&quot;&gt;default expiration&lt;/code&gt; for his key.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;He entered his &lt;code class=&quot;highlighter-rouge&quot;&gt;real name and email address&lt;/code&gt;. Sherlock provided the verified email address for his GitHub account. This will make it very easy to link his account with his Public Key.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Provide a &lt;code class=&quot;highlighter-rouge&quot;&gt;secure passphrase&lt;/code&gt;. Choose wisely and be sure to remember it because else the key cannot be used and any data encrypted using that key will be lost.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Congratulations, a newly fresh Key Pair should be generated now.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;      &lt;span class=&quot;c&quot;&gt;# List all keys.
&lt;/span&gt;
      &lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;gpg --list-keys
        pub   4096R/90C3C3DE 2016-07-24
        uid     Sherlock H &amp;lt;sherlock.h@bakerstreet.org&amp;gt;
        sub   4096R/586B3A7B 2016-07-24
      &lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;ul&gt;
  &lt;li&gt;Like many other developers, Sherlock is very active on GitHub and would like to link his Public Key with his account. He therefore will need to create a textual version of his Public Key. After having executed the command below, the content of the generated ‘pubkey.txt’ needs to be added to his account as described in the &lt;a href=&quot;https://help.github.com/articles/adding-a-new-gpg-key-to-your-github-account/&quot;&gt;GitHub Help pages&lt;/a&gt;. More details about distributing and registering your Public Key to a key server can be found in the chapter ‘&lt;a href=&quot;https://www.gnupg.org/gph/en/manual.html#AEN464&quot;&gt;Distributing keys&lt;/a&gt;’ of the GPG Users Guide. For other usages like encryption and decryption, please refer to &lt;a href=&quot;http://www.dewinter.com/gnupg_howto/english/GPGMiniHowto.html&quot;&gt;GPG’s Mini HowTo&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;    &lt;span class=&quot;c&quot;&gt;# Export the Public Key to a text file.
&lt;/span&gt;
    &lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;gpg --armor --output pubkey.txt --export &lt;span class=&quot;s1&quot;&gt;'Sherlock H'&lt;/span&gt;
    &lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;h2 id=&quot;signing-your-work&quot;&gt;Signing Your Work&lt;/h2&gt;
&lt;p&gt;Once Sherlock generated his Key Pair, he can configure Git to use it for signing commits and tags. Following tools can be used to store a GPG key passphrase in a keychain so he doesn’t have to provide it every time he signs a commit: &lt;a href=&quot;https://gpgtools.org/&quot;&gt;GPG Suite&lt;/a&gt; (Mac) or &lt;a href=&quot;https://www.gpg4win.org/&quot;&gt;Gpg4win&lt;/a&gt; (Windows).&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;  &lt;span class=&quot;c&quot;&gt;# Set the signing key by taking your Public Key id as parameter.
&lt;/span&gt;
  &lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;git config --global user.signingkey 90C3C3DE

  &lt;span class=&quot;c&quot;&gt;# Automatically signs every commit.
&lt;/span&gt;
  &lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;git config --global commit.gpgsign &lt;span class=&quot;nb&quot;&gt;true&lt;/span&gt;

  &lt;span class=&quot;c&quot;&gt;# Manually sign a commit.
&lt;/span&gt;
  &lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;git commit -S -m &lt;span class=&quot;s2&quot;&gt;&quot;some commit message&quot;&lt;/span&gt;

  &lt;span class=&quot;c&quot;&gt;# Verify whether your commit has been signed.
&lt;/span&gt;
  &lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;git log --show-signature

    commit 81314da640320c65896a4348842d303a754f37d2
    gpg: Signature made Sun Jul 24 15:02:25 2016 CEST using RSA key ID 90C3C3DE
    gpg: Good signature from &lt;span class=&quot;s2&quot;&gt;&quot;Sherlock H &amp;lt;sherlock.h@bakerstreet.org&amp;gt;&quot;&lt;/span&gt;
    Author: Sherlock H &amp;lt;sherlock.h@bakerstreet.org&amp;gt;
    Date:   Sun Jul 24 15:01:52 2016 +0200

  &lt;span class=&quot;c&quot;&gt;# Verify all signatures during merge. If the signatures can not be verified then merge will be aborted.
&lt;/span&gt;
  &lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;git merge --verify-signatures other_branch
  &lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;Earlier this year GitHub &lt;a href=&quot;https://github.com/blog/2144-gpg-signature-verification&quot;&gt;announced&lt;/a&gt; that they now will show when commits and tags are signed and verified using any of the contributor’s GPG keys upload to GitHub. Keep your eyes open for commits and tags labeled with those green &lt;code class=&quot;highlighter-rouge&quot;&gt;verified&lt;/code&gt; badges.&lt;/p&gt;

&lt;h2 id=&quot;secure-by-design&quot;&gt;Secure-By-Design&lt;/h2&gt;
&lt;p&gt;Ordina’s &lt;a href=&quot;https://www.ordina.be/en/services-et-solutions/themas/secure-by-design/&quot;&gt;Secure-By-Design programme&lt;/a&gt; encourages to consider and take account of possible security risks as early as possible in a business process.
So follow Sherlock’s example by embedding and safeguarding security in your daily work as a developer and &lt;strong&gt;Sign Your Work!&lt;/strong&gt;&lt;/p&gt;

&lt;h2 id=&quot;resources&quot;&gt;Resources&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://help.github.com/categories/gpg/&quot;&gt;GitHub’s Help on GPG&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.gnupg.org/gph/en/manual/book1.html&quot;&gt;The GNU Privacy Handbook&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.dewinter.com/gnupg_howto/english/GPGMiniHowto.html&quot;&gt;GPG’s Mini HowTo&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://mikegerwitz.com/papers/git-horror-story&quot;&gt;“A Git Horror Story”&lt;/a&gt; by Mike Gerwitz&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=wXB-V_Keiu8&quot;&gt;“Public Key Cryptography: RSA Encryption Algorithm”&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Mon, 25 Jul 2016 00:00:00 +0000</pubDate>
        <link>https://ordina-jworks.github.io/security/2016/07/25/Web-of-trusted-commits.html</link>
        <guid isPermaLink="true">https://ordina-jworks.github.io/security/2016/07/25/Web-of-trusted-commits.html</guid>
        
        <category>Security</category>
        
        <category>Git</category>
        
        <category>Encryption</category>
        
        <category>Digital Signature</category>
        
        <category>Cryptography</category>
        
        
        <category>Security</category>
        
      </item>
    
      <item>
        <title>Spring I/O 16: Bridging the worlds of DDD &amp; REST</title>
        <description>&lt;p&gt;&lt;a href=&quot;http://www.springio.net&quot;&gt;SpringIO 2016 in Barcelona&lt;/a&gt; was loaded with tons of interesting talks and workshops about Spring Cloud, Spring Boot, Spring Data, Microservices, REST &amp;amp; HATEOAS, Reactive programming, and many many more.
In this blogpost I will highlight Oliver Gierke’s 2 hour presentation about bridging the world of Domain Driven Design (DDD) and the world of Representational State Transfer (REST).&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;p-image float-image&quot; width=&quot;200&quot; alt=&quot;Oliver Gierke&quot; src=&quot;/img/ddd-rest/oliver-gierke.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Oliver Gierke (&lt;a href=&quot;https://twitter.com/olivergierke&quot;&gt;@olivergierke&lt;/a&gt;) is the lead of the Spring Data project at Pivotal and member of the JPA 2.1 expert group. He has been into developing enterprise applications and open source projects for over 10 years. His working focus is centered around software architecture, DDD, REST, and persistence technologies.&lt;/p&gt;

&lt;h2 id=&quot;domain-driven-design&quot;&gt;Domain Driven Design&lt;/h2&gt;
&lt;p&gt;DDD is an approach to developing software that meets core business objectives by providing on the one hand tactical modeling tools which include well founded patterns and concepts such as entities, repositories and factories. On the other hand DDD also facilitates strategic principles and methodologies for analyzing and modeling domains such as Bounded Contexts and Context Maps.&lt;/p&gt;

&lt;p&gt;For an in depth understanding of DDD I highly recommend reading &lt;a href=&quot;http://dddcommunity.org/book/evans_2003/&quot;&gt;“Domain Driven Design - Tackling Complexity in the Heart of Software”&lt;/a&gt; by Eric Evans (&lt;a href=&quot;https://twitter.com/ericevans&quot;&gt;@ericevans0&lt;/a&gt;). There’s also a &lt;a href=&quot;https://www.infoq.com/minibooks/domain-driven-design-quickly&quot;&gt;short, quick-readable summary and introduction&lt;/a&gt; to the fundamentals of DDD made available by InfoQ.&lt;/p&gt;

&lt;p&gt;Oliver’s talk at SpringIO 2016 highlighted a few basic DDD concepts like Entities, Value Objects, Repositories, Aggregates and Bounded Contexts.&lt;/p&gt;

&lt;h3 id=&quot;value-objects&quot;&gt;Value Objects&lt;/h3&gt;

&lt;blockquote&gt;
  &lt;p&gt;Avoid Stringly typed code&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;Value Objects&lt;/strong&gt; are vital building blocks of DDD. They are small immutable objects that encapsulate value, validation and behaviour. You can use them to group related values together and provide functionality related to what they represent, making implicit concepts explicit.
Some common use cases for VOs are: EmailAddress, Money, ZIPCode, Status, … avoid writing these as just plain Strings!&lt;/p&gt;

&lt;p&gt;Writing VOs can be a cumbersome task but there are some source code generator frameworks out there like &lt;a href=&quot;https://projectlombok.org/&quot;&gt;Project Lombok&lt;/a&gt; and &lt;a href=&quot;https://github.com/google/auto&quot;&gt;Google’s AutoValue&lt;/a&gt; which can handle all the boilerplate code.&lt;/p&gt;

&lt;h3 id=&quot;entities--repositories&quot;&gt;Entities &amp;amp; Repositories&lt;/h3&gt;
&lt;p&gt;In contrast to Value Objects which are identified by the attributes they carry, &lt;strong&gt;Entities&lt;/strong&gt; are distinguished by their identity. Entity objects have a life cycle because their identity defines their responsibilities and associations. It is this unique identity and their mutability that sets Entities apart from Value Objects. This means that two Value Objects with the same properties should be considered the same whereas two Entities differ even if their properties match.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Aggregates form nice representation boundaries and become the key things to refer to.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;An &lt;strong&gt;Aggregate&lt;/strong&gt; is a cluster of closely related entities that can be treated as a single unit. The common parent of that cluster is called an &lt;strong&gt;Aggregate Root&lt;/strong&gt;. An example can be an Order and its Line Items, these will be separate objects but it is useful to treat the Order (the Aggregate Root) together with its Line Items as a single Aggregate.&lt;/p&gt;

&lt;p&gt;When trying to discover Aggregates, we should understand the model’s invariants. An invariant is a business rule that must always be consistent and usually refers to &lt;strong&gt;transactional consistency&lt;/strong&gt;. When a transaction commits then everything inside the Aggregate should be consistent and any subsequent access by any client should return the updated value. In most cases it is a best practice to modify only one Aggregate in a single transaction. For updating multiple aggregates &lt;strong&gt;eventual consistency&lt;/strong&gt; can be used. There will be an inconsistency window during which an access may return either the old or the new value but eventually all accesses will return the last updated value. The duration of the inconsistency window can be calculated based on factors like network delays, number of copies of the object, and the system load.&lt;/p&gt;

&lt;p&gt;A &lt;strong&gt;Repository&lt;/strong&gt; is an abstraction over a persistence store for Aggregates. It acts like a collection by exposing methods to add and remove objects which encapsulate the actual interaction with the underlying data store. It also has elaborate query capabilities which return fully instantiated Aggregates whose attributes values meet the criteria.&lt;/p&gt;

&lt;h3 id=&quot;bounded-context&quot;&gt;Bounded Context&lt;/h3&gt;
&lt;p&gt;DDD aims to create software models based on the underlying domain. A &lt;strong&gt;Bounded Context&lt;/strong&gt; is the boundary that surrounds a part of a particular domain. This boundary isolates the model and language from other models and therefore helps reducing ambiguity and clarifying the meaning. When the boundaries are chosen well, greater decoupling between systems can be achieved which allows to easily change or replace the internals of a BC. Avoid having transactions across multiple BCs.&lt;/p&gt;

&lt;p&gt;The language that is structured around the domain model is called the &lt;strong&gt;Ubiquitous Language&lt;/strong&gt;. It is important that this language is used by all team members (developers, analysts, business stakeholders, …) to connect all the activities of the team with the software. The vocabulary on its own does not have any relevance, it only has meaning inside a certain context. For example, an Item has a different meaning in the Orders BC than in the Products BC.&lt;/p&gt;

&lt;h3 id=&quot;domain-events&quot;&gt;Domain Events&lt;/h3&gt;
&lt;p&gt;A &lt;strong&gt;Domain Event&lt;/strong&gt; is an extremely powerful tool in DDD. It is a type of message that describes something that has happened in the past and that is of interest to the business. (e.g. OrderShipped, CustomerBecamePreferred, …). It is important to model Event names and its properties according to the Ubiquitous Language of the BC where they originated. When Events need to be delivered to interested parties in either a local BC or broadcasted across BCs eventually consistency is generally used.&lt;/p&gt;

&lt;h3 id=&quot;maturity-level&quot;&gt;Maturity Level&lt;/h3&gt;
&lt;p&gt;The maturity level of the use of Domain Events can be categorized into 4 levels:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Level 0&lt;/strong&gt;: no events at all
    &lt;ul&gt;
      &lt;li&gt;procedural code with just getters and setters&lt;/li&gt;
      &lt;li&gt;data just goes in and out&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Level 1&lt;/strong&gt;: explicit operations&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Level 2&lt;/strong&gt;: some operations as events
    &lt;ul&gt;
      &lt;li&gt;domain events are used as state transition&lt;/li&gt;
      &lt;li&gt;important domain events are exposed to interested parties via feeds&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Level 3&lt;/strong&gt;: event sourcing - all changes to application state are stored as a sequence of events
    &lt;ul&gt;
      &lt;li&gt;only event logs and snapshots are kept (Event Store)&lt;/li&gt;
      &lt;li&gt;separation of read and write operations (CQRS)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;rest&quot;&gt;REST&lt;/h2&gt;

&lt;blockquote&gt;
  &lt;p&gt;REST ≠ CRUD via HTTP. Representation design matters.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;resources&quot;&gt;Resources&lt;/h3&gt;
&lt;p&gt;Just like an Aggregate, a well designed &lt;strong&gt;Resource&lt;/strong&gt; should be identifiable, referable and should have a clear scope of consistency.&lt;/p&gt;

&lt;p&gt;Exposing the core domain model directly via RESTful HTTP can lead to brittle REST interfaces because each change in the domain model will be reflected in the interface. Decoupling the core domain from the REST interface has the advantage that we can make changes to the domain and then decide in each individual case whether a change is needed in the REST interface and how to map it.&lt;/p&gt;

&lt;p&gt;Also avoid using HTTP PATCH or PUT for (complex) state transitions of your business domain because you are missing out on a lot of information regarding the real business domain event that triggered this update. For example, changing a customer’s mailing address is a POST to a new “ChangeOfAddress” resource, not a PATCH or PUT of a “Customer” resource with a different mailing address field value.
This goes hand in hand with DDD’s concept of &lt;strong&gt;Event Sourcing&lt;/strong&gt; because those state transitions are domain relevant events, not just some changes to the state of some object.&lt;/p&gt;

&lt;h3 id=&quot;hateoas&quot;&gt;HATEOAS&lt;/h3&gt;
&lt;p&gt;A RESTful HTTP client can navigate from resource to resource in two different ways. Firstly by being redirected as a result of sending data for processing to the server, and secondly by following links contained in the response of the server. The latter technique is called &lt;strong&gt;Hypermedia as the Engine of Application State&lt;/strong&gt; or HATEOAS.&lt;/p&gt;

&lt;p&gt;The goal of Hypermedia is to serve not only data but also navigation information at the same time. This has a great impact on the client architecture because now we’re trading domain knowledge with protocol complexity. The client becomes dumber because it no longer needs to know business rules in a sense that its decisions are reduced to checking whether a link is present or not, e.g. whenever there’s a cancel link in the HTTP response, then display the Cancel button. This will make the client’s behavior more dynamic.
On the other hand, the client becomes smarter because it needs to handle a smarter and more comprehensive protocol.&lt;/p&gt;

&lt;h3 id=&quot;maturity-level-1&quot;&gt;Maturity level&lt;/h3&gt;
&lt;p&gt;In analogy to the maturity level of Aggregates described earlier, &lt;strong&gt;Leonard Richardson’s model&lt;/strong&gt; can be used to determine the maturity or our REST services.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Level 0&lt;/strong&gt;: Swamp of POX
    &lt;ul&gt;
      &lt;li&gt;the HTTP protocol is used to make RPC calls without indication of the application state&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Level 1&lt;/strong&gt;: Resources
    &lt;ul&gt;
      &lt;li&gt;exposure of multiple URIs and each one is an entry point to a specific resource, e.g. http://example.org/orders, http://example.org/order/1, http://example.org/order/2&lt;/li&gt;
      &lt;li&gt;use of only one single method like POST.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Level 2&lt;/strong&gt;: HTTP verbs
    &lt;ul&gt;
      &lt;li&gt;use of HTTP protocol properties (POST, GET, DELETE, …)&lt;/li&gt;
      &lt;li&gt;use of HTTP response codes, e.g. HTTP 200 (OK)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Level 3&lt;/strong&gt;: Hypermedia controls
    &lt;ul&gt;
      &lt;li&gt;refer to description earlier in this blog post.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;translating-domain-concepts-into-web-appropriate-ones&quot;&gt;Translating domain concepts into web appropriate ones&lt;/h3&gt;

&lt;table class=&quot;table table-striped&quot;&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;DDD&lt;/th&gt;
      &lt;th&gt;REST&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Aggregate Root / Repository&lt;/td&gt;
      &lt;td&gt;Collection / Item Resource&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Relations&lt;/td&gt;
      &lt;td&gt;Links&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;IDs&lt;/td&gt;
      &lt;td&gt;URIs&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;@Version&lt;/td&gt;
      &lt;td&gt;ETags&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Last Modified Property&lt;/td&gt;
      &lt;td&gt;Last Modified Header&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h3 id=&quot;sample-implementation&quot;&gt;Sample implementation&lt;/h3&gt;
&lt;p&gt;Oliver also prepared a small sample implementation using Spring Boot, Spring Data and Lombok. The project is called &lt;a href=&quot;https://github.com/olivergierke/spring-restbucks&quot;&gt;Spring RESTBucks&lt;/a&gt; and is definitely worth checking out!&lt;/p&gt;

&lt;h2 id=&quot;resources-1&quot;&gt;Resources&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://speakerdeck.com/olivergierke/domain-driven-design-and-rest-1&quot;&gt;“DDD &amp;amp; REST”&lt;/a&gt; (slide deck used at SpringIO 2016) by Oliver Gierke&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/olivergierke/spring-restbucks&quot;&gt;“Spring RESTBucks”&lt;/a&gt; (sample project used at SpringIO 2016) by Oliver Gierke&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://olivergierke.de/2016/04/benefits-of-hypermedia/&quot;&gt;“Benefits of hypermedia”&lt;/a&gt; by Oliver Gierke&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://dddcommunity.org/book/evans_2003/&quot;&gt;“Domain Driven Design - Tackling Complexity in the Heart of Software”&lt;/a&gt; by Eric Evans&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://dddcommunity.org/book/implementing-domain-driven-design-by-vaughn-vernon/&quot;&gt;“Implementing Domain Driven Design”&lt;/a&gt; by Vaughn Vernon&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.infoq.com/minibooks/domain-driven-design-quickly&quot;&gt;“Domain Driven Design Quickly”&lt;/a&gt; by InfoQ&lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Sun, 10 Jul 2016 00:00:00 +0000</pubDate>
        <link>https://ordina-jworks.github.io/conferences/2016/07/10/SpringIO16-DDD-Rest.html</link>
        <guid isPermaLink="true">https://ordina-jworks.github.io/conferences/2016/07/10/SpringIO16-DDD-Rest.html</guid>
        
        <category>Spring IO</category>
        
        <category>Spring</category>
        
        <category>Conference</category>
        
        
        <category>Conferences</category>
        
      </item>
    
  </channel>
</rss>
